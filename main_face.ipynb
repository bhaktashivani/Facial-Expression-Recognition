{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 285 Final Project: Facial Expression Recognition\n",
    "#### By Shivani Bhakta and Payal Singh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image, ImageOps, ImageEnhance, ImageFilter \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import cv2 \n",
    "import sys\n",
    "import copy\n",
    "\n",
    "from woodnet import *\n",
    "from MyNet import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop and resize images\n",
    "- We use the MTCNN face detector to recognize face in our dataset and crop each images and resize them to 224 x 224. Do this by running the PrepData.py file. Use the command ``` python PrepData.py``` in terminal\n",
    "- We then store them into a new folder\n",
    "- https://www.kaggle.com/timesler/guide-to-mtcnn-in-facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tufts Face DB \n",
    "In this project we use a dataset named Tufts Face Database for Facial Recognition. This dataset is made up with over 10,000 images of 74 female and 38 males from more than 15 countries with the age range between 4-70 years old. This dataset contains 7 image modalities, but we only use a subset of it, from the Tufts Face Database 2D RGB Expression (TDRGBA). This set contains 5 images of 50 different people. These 5 images are of 5 different expressions (neutral, smiling, eyes closed, surprised, and sunglasses). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "person = 1    # do not choose 47 (this participant withdrew from the dataset)\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(24, 16))\n",
    "\n",
    "if person == 47: \n",
    "    print('Cannot display Participant 47')\n",
    "for idx in np.arange(1, 6):\n",
    "    # original dataset images\n",
    "    orig_im = Image.open(f'dataset/{person}/TD_RGB_E_{idx}.jpg')\n",
    "    # cropped dataset images\n",
    "    im = Image.open(f'cropped/TD_RGB_E_{person}_{idx}.jpg')\n",
    "    # Display all of the images of selected person\n",
    "    axes[idx-1][0].axis('off')\n",
    "    axes[idx-1][0].imshow(orig_im)\n",
    "    axes[idx-1][0].set_title(f'Original dataset: person {person}, image {idx}')\n",
    "    axes[idx-1][1].axis('off')\n",
    "    axes[idx-1][1].imshow(im)\n",
    "    axes[idx-1][1].set_title(f'Cropped dataset: person {person}, image {idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "def get_faces():\n",
    "    '''\n",
    "    input: \n",
    "        n: number of images to load from the folder. \n",
    "    output: \n",
    "        neutral_faces: numpy array with each column corresponds to a data point (each image of neutral faces) \n",
    "        smiling_faces: numpy array with each column corresponds to a data point (each image of smiling faces)\n",
    "    '''\n",
    "    n = 49    # number of people in dataset\n",
    "    \n",
    "    neutral_faces = np.zeros((n,3,224,224))\n",
    "    smiling_faces = np.zeros((n,3,224,224))\n",
    "    eyesclosed_faces = np.zeros((n,3,224,224))\n",
    "    surprised_faces = np.zeros((n,3,224,224))\n",
    "    sunglasses_faces = np.zeros((n,3,224,224))\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        if i == 47: continue\n",
    "        for j in range(1,6):\n",
    "            image_path = f'cropped/TD_RGB_E_{i}_{j}.jpg'\n",
    "            p = Image.open(image_path)\n",
    "            # this is where to do data augmentation\n",
    "            p = np.transpose(np.array(p))\n",
    "        \n",
    "            if j == 1: neutral_faces[i-1,:] = p\n",
    "            elif j == 2: smiling_faces[i-1,:] = p\n",
    "            elif j ==3: eyesclosed_faces[i-1,:] = p\n",
    "            elif j == 4: surprised_faces[i-1,:] = p\n",
    "            elif j == 5: sunglasses_faces[i-1,:] = p\n",
    "\n",
    "    return neutral_faces, smiling_faces, eyesclosed_faces, surprised_faces, sunglasses_faces\n",
    "\n",
    "neutral_faces, smiling_faces, eyesclosed_faces, surprised_faces, sunglasses_faces = get_faces()\n",
    "print(neutral_faces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "def augmentation_and_transp(p):\n",
    "    \n",
    "    # flip image across vertical axis\n",
    "    p1 = p.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "    # rotate images by 5 and 10 degrees to either side\n",
    "    p2 = p.rotate(5)\n",
    "    p3 = p.rotate(-5)\n",
    "    p4 = p.rotate(10)\n",
    "    p5 = p.rotate(-10)\n",
    "    # change image brightness\n",
    "    enhancer = ImageEnhance.Brightness(p)\n",
    "    p6 = enhancer.enhance(0.5)\n",
    "    p7 = enhancer.enhance(1.5)\n",
    "    # Gaussian blur images\n",
    "    p8 = p.filter(ImageFilter.GaussianBlur(radius = 5))\n",
    "    # translate images to left/right/up/down \n",
    "#     p9 = p.transform(p.size, Image.AFFINE, (1, 0, 5, 0, 0, 5))\n",
    "#     p10 = p.transform(p.size, Image.AFFINE, (1, 0, -5, 0, 0, -5))\n",
    "#     p11 = p.transform(p.size, Image.AFFINE, (1, 0, 10, 0, 0, 10))\n",
    "#     p12 = p.transform(p.size, Image.AFFINE, (1, 0, -10, 0, 0, -10))\n",
    "    \n",
    "    p9 = p.transform(p.size, Image.AFFINE, (1, 0, 5, 0, 1, 5))\n",
    "    p10 = p.transform(p.size, Image.AFFINE, (1, 0, -5, 0,1, -5))\n",
    "    p11 = p.transform(p.size, Image.AFFINE, (1, 0, 10, 0, 1, 10))\n",
    "    p12 = p.transform(p.size, Image.AFFINE, (1, 0, -10, 0, 1, -10))\n",
    "    # normalize\n",
    "    p = np.transpose(np.array(p).astype('float32')/255.0)\n",
    "    p1 = np.transpose(np.array(p1).astype('float32')/255.0)\n",
    "    p2 = np.transpose(np.array(p2).astype('float32')/255.0)\n",
    "    p3 = np.transpose(np.array(p3).astype('float32')/255.0)\n",
    "    p4 = np.transpose(np.array(p4).astype('float32')/255.0)\n",
    "    p5 = np.transpose(np.array(p5).astype('float32')/255.0)\n",
    "    p6 = np.transpose(np.array(p6).astype('float32')/255.0)\n",
    "    p7 = np.transpose(np.array(p7).astype('float32')/255.0)\n",
    "    p8 = np.transpose(np.array(p8).astype('float32')/255.0)\n",
    "    p9 = np.transpose(np.array(p9).astype('float32')/255.0)\n",
    "    p10 = np.transpose(np.array(p10).astype('float32')/255.0)\n",
    "    p11 = np.transpose(np.array(p11).astype('float32')/255.0)\n",
    "    p12 = np.transpose(np.array(p12).astype('float32')/255.0)\n",
    "    \n",
    "    return p, p1,  p2,  p3, p4,  p5, p6, p7, p8, p9, p10, p11, p12\n",
    "\n",
    "def get_faces1():\n",
    "    '''\n",
    "    input: \n",
    "        n: number of images to load from the folder. \n",
    "    output: \n",
    "        neutral_faces: numpy array with each column corresponds to a data point (each image of neutral faces) \n",
    "        smiling_faces: numpy array with each column corresponds to a data point (each image of smiling faces)\n",
    "    '''\n",
    "    n = 49    # number of people in dataset\n",
    "    \n",
    "    neutral_faces = []\n",
    "    smiling_faces = []\n",
    "    eyesclosed_faces = []\n",
    "    surprised_faces = []\n",
    "    sunglasses_faces = []\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        if i == 47: continue\n",
    "        for j in range(1,6):\n",
    "            image_path = f'cropped/TD_RGB_E_{i}_{j}.jpg'\n",
    "            p = Image.open(image_path)\n",
    "            p, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12 = augmentation_and_transp(p)    # data augmentation and transposing\n",
    "        \n",
    "            if j == 1: \n",
    "                neutral_faces.extend([p, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12])\n",
    "            elif j == 2: \n",
    "                smiling_faces.extend([p, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12])\n",
    "            elif j ==3: \n",
    "                eyesclosed_faces.extend([p, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12])\n",
    "            elif j == 4: \n",
    "                surprised_faces.extend([p, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12])\n",
    "            elif j == 5: \n",
    "                sunglasses_faces.extend([p, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12])\n",
    "\n",
    "    return np.array(neutral_faces), np.array(smiling_faces), np.array(eyesclosed_faces), np.array(surprised_faces), np.array(sunglasses_faces)\n",
    "\n",
    "neutral_faces, smiling_faces, eyesclosed_faces, surprised_faces, sunglasses_faces = get_faces1()\n",
    "print(np.shape(neutral_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data shape:  (3120, 3, 224, 224)\n",
      "Train data shape:  (2773, 3, 224, 224)\n",
      "Test data shape:  (347, 3, 224, 224)\n",
      "Individual Image size:  (1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "data = np.vstack((neutral_faces, smiling_faces, eyesclosed_faces, surprised_faces, sunglasses_faces))\n",
    "labels_0 = [0] * len(neutral_faces)\n",
    "labels_1 = [1] * len(smiling_faces)\n",
    "labels_2 = [2] * len(eyesclosed_faces)\n",
    "labels_3 = [3] * len(surprised_faces)\n",
    "labels_4 = [4] * len(sunglasses_faces)\n",
    "\n",
    "labels = labels_0 + labels_1 + labels_2 + labels_3 + labels_4\n",
    "labels = np.array(labels)\n",
    "idxs = list(range(np.shape(neutral_faces)[0]*5))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "data = data[idxs]\n",
    "labels = labels[idxs]\n",
    "print(\"Total data shape: \", data.shape)\n",
    "\n",
    "test_train_split = 0.88889\n",
    "train_data = data[:int(test_train_split * len(idxs))]\n",
    "train_labels = labels[:int(test_train_split * len(idxs))]\n",
    "print(\"Train data shape: \", train_data.shape)\n",
    "\n",
    "test_data = data[int(test_train_split * len(idxs)):]\n",
    "test_labels = labels[int(test_train_split * len(idxs)):]\n",
    "print(\"Test data shape: \", test_data.shape)\n",
    "\n",
    "image = test_data[0]\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "print(\"Individual Image size: \", image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    ''' This class formats the dataset into a iterable-style dataset needed for the dataloader'''\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1,2,0))\n",
    "            x = self.transform(x)\n",
    "        data = {'x': x, 'y': y}\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "train_data = MyDataset(train_data, train_labels)\n",
    "test_data = MyDataset(test_data, test_labels)\n",
    "# dataloader = DataLoader(dataset, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to check the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = len(train_data)\n",
    "NUM_TEST = len(test_data)\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "  \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    loss = 0.00\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            x = data['x'].to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = data['y'].to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "            \n",
    "            loss = F.cross_entropy(scores,y) + loss\n",
    "            \n",
    "        acc = float(num_correct) / num_samples\n",
    "        loss = loss/ num_samples\n",
    "        \n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        \n",
    "        return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function for training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    loss_arr = []\n",
    "    test_loss_arr = []\n",
    "    test_acc_arr =[]\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "  \n",
    "    for e in range(epochs):\n",
    "        model.train() # put model to training mode\n",
    "        for t, data in enumerate(loader_train):\n",
    "            x = data['x'].to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = data['y'].to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "            \n",
    "            if t == 0:\n",
    "                iter_loss = loss.item()\n",
    "            else:\n",
    "                iter_loss = iter_loss + loss.item()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print(f'Epoch {e}, Iteration {t}, loss = {loss.item():.7f}')\n",
    "#                 acc_Val, loss_Val = check_accuracy(loader_val, model)\n",
    "#                 print()\n",
    "        loss_arr.append(iter_loss/t)\n",
    "    \n",
    "        model.eval()\n",
    "        acc_Val, loss_Val = check_accuracy(loader_test, model)\n",
    "        test_loss_arr.append(loss_Val)\n",
    "        test_acc_arr.append(acc_Val)\n",
    "    \n",
    "    # plot loss and accuracy\n",
    "    f, axes = plt.subplots(2, constrained_layout=True)\n",
    "    axes[0].plot(loss_arr, label=\"Train loss\")\n",
    "#     axes[0].plot(test_loss_arr, label = 'Test loss')\n",
    "    axes[0].set_title('Loss History')\n",
    "    axes[0].set_xlabel('Iteration')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend(loc='upper right')\n",
    "    \n",
    "    axes[1].plot(test_acc_arr, label=\"Test accuracy\")\n",
    "    axes[1].set_title('Accuracy History')\n",
    "    axes[1].set_xlabel('Iteration')\n",
    "    axes[1].set_ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(train_data, batch_size=12, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "# loader_val = DataLoader(cifar100_val, batch_size=batch_size, num_workers=2, \n",
    "#                         sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "# cifar100_test = dset.CIFAR100('./datasets/cifar100', train=False, download=True, \n",
    "#                             transform=transform_test)\n",
    "loader_test = DataLoader(test_data, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WoodNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define WoodNet\n",
    "model = WoodNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)\n",
    "\n",
    "print_every = 10\n",
    "train_model(model, optimizer, epochs=50)\n",
    "# without data augmentation, test accuracy was 20/28 ~= 71.4%\n",
    "# with data augmentation and normalization, test accuracy was  ~= %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set accuracy\n",
    "check_accuracy(loader_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0, loss = 1.5948862\n",
      "Epoch 0, Iteration 10, loss = 1.4240540\n",
      "Epoch 0, Iteration 20, loss = 1.4412404\n",
      "Epoch 0, Iteration 30, loss = 1.4615480\n",
      "Epoch 0, Iteration 40, loss = 0.9442244\n",
      "Epoch 0, Iteration 50, loss = 1.0433859\n",
      "Epoch 0, Iteration 60, loss = 1.4166660\n",
      "Epoch 0, Iteration 70, loss = 1.0442373\n",
      "Epoch 0, Iteration 80, loss = 0.6835582\n",
      "Epoch 0, Iteration 90, loss = 1.2977506\n",
      "Epoch 0, Iteration 100, loss = 0.8426530\n",
      "Epoch 0, Iteration 110, loss = 0.9819648\n",
      "Epoch 0, Iteration 120, loss = 0.7738685\n",
      "Epoch 0, Iteration 130, loss = 0.5957798\n",
      "Epoch 0, Iteration 140, loss = 0.7498004\n",
      "Epoch 0, Iteration 150, loss = 0.4894474\n",
      "Epoch 0, Iteration 160, loss = 0.6577056\n",
      "Epoch 0, Iteration 170, loss = 0.7171664\n",
      "Epoch 0, Iteration 180, loss = 0.9381742\n",
      "Epoch 0, Iteration 190, loss = 0.8437343\n",
      "Epoch 0, Iteration 200, loss = 0.6729899\n",
      "Epoch 0, Iteration 210, loss = 0.4850965\n",
      "Epoch 0, Iteration 220, loss = 0.8414070\n",
      "Epoch 0, Iteration 230, loss = 0.8311670\n",
      "Got 82 / 347 correct (23.63)\n",
      "Epoch 1, Iteration 0, loss = 1.0014626\n",
      "Epoch 1, Iteration 10, loss = 0.6549243\n",
      "Epoch 1, Iteration 20, loss = 1.1097504\n",
      "Epoch 1, Iteration 30, loss = 0.9388562\n",
      "Epoch 1, Iteration 40, loss = 0.7114691\n",
      "Epoch 1, Iteration 50, loss = 0.5255648\n",
      "Epoch 1, Iteration 60, loss = 0.7808117\n",
      "Epoch 1, Iteration 70, loss = 0.1682112\n",
      "Epoch 1, Iteration 80, loss = 0.3748372\n",
      "Epoch 1, Iteration 90, loss = 0.3477770\n",
      "Epoch 1, Iteration 100, loss = 0.7236515\n",
      "Epoch 1, Iteration 110, loss = 0.3377803\n",
      "Epoch 1, Iteration 120, loss = 0.4010515\n",
      "Epoch 1, Iteration 130, loss = 0.6225886\n",
      "Epoch 1, Iteration 140, loss = 0.5122895\n",
      "Epoch 1, Iteration 150, loss = 0.4898550\n",
      "Epoch 1, Iteration 160, loss = 0.6063352\n",
      "Epoch 1, Iteration 170, loss = 0.4186818\n",
      "Epoch 1, Iteration 180, loss = 0.2804917\n",
      "Epoch 1, Iteration 190, loss = 0.4223706\n",
      "Epoch 1, Iteration 200, loss = 0.3517324\n",
      "Epoch 1, Iteration 210, loss = 0.5934141\n",
      "Epoch 1, Iteration 220, loss = 0.6702624\n",
      "Epoch 1, Iteration 230, loss = 0.7428449\n",
      "Got 84 / 347 correct (24.21)\n",
      "Epoch 2, Iteration 0, loss = 0.8000281\n",
      "Epoch 2, Iteration 10, loss = 0.2164429\n",
      "Epoch 2, Iteration 20, loss = 0.2702525\n",
      "Epoch 2, Iteration 30, loss = 0.6973951\n",
      "Epoch 2, Iteration 40, loss = 0.7098200\n",
      "Epoch 2, Iteration 50, loss = 0.2158960\n",
      "Epoch 2, Iteration 60, loss = 0.5105925\n",
      "Epoch 2, Iteration 70, loss = 0.2760509\n",
      "Epoch 2, Iteration 80, loss = 0.5254831\n",
      "Epoch 2, Iteration 90, loss = 0.4345557\n",
      "Epoch 2, Iteration 100, loss = 0.2540579\n",
      "Epoch 2, Iteration 110, loss = 0.3983756\n",
      "Epoch 2, Iteration 120, loss = 0.3593056\n",
      "Epoch 2, Iteration 130, loss = 0.4571129\n",
      "Epoch 2, Iteration 140, loss = 0.6111343\n",
      "Epoch 2, Iteration 150, loss = 0.8222620\n",
      "Epoch 2, Iteration 160, loss = 0.3768765\n",
      "Epoch 2, Iteration 170, loss = 0.1395945\n",
      "Epoch 2, Iteration 180, loss = 0.1531373\n",
      "Epoch 2, Iteration 190, loss = 0.1347706\n",
      "Epoch 2, Iteration 200, loss = 0.3437597\n",
      "Epoch 2, Iteration 210, loss = 0.5051488\n",
      "Epoch 2, Iteration 220, loss = 0.2319293\n",
      "Epoch 2, Iteration 230, loss = 0.1135324\n",
      "Got 113 / 347 correct (32.56)\n",
      "Epoch 3, Iteration 0, loss = 0.0898960\n",
      "Epoch 3, Iteration 10, loss = 0.1405151\n",
      "Epoch 3, Iteration 20, loss = 0.1348771\n",
      "Epoch 3, Iteration 30, loss = 0.1089590\n",
      "Epoch 3, Iteration 40, loss = 0.3197541\n",
      "Epoch 3, Iteration 50, loss = 0.2714573\n",
      "Epoch 3, Iteration 60, loss = 0.2847601\n",
      "Epoch 3, Iteration 70, loss = 0.3920284\n",
      "Epoch 3, Iteration 80, loss = 0.2844950\n",
      "Epoch 3, Iteration 90, loss = 0.0192392\n",
      "Epoch 3, Iteration 100, loss = 0.6306834\n",
      "Epoch 3, Iteration 110, loss = 0.1101201\n",
      "Epoch 3, Iteration 120, loss = 0.2891812\n",
      "Epoch 3, Iteration 130, loss = 0.2619140\n",
      "Epoch 3, Iteration 140, loss = 0.1359175\n",
      "Epoch 3, Iteration 150, loss = 0.0591871\n",
      "Epoch 3, Iteration 160, loss = 0.5329434\n",
      "Epoch 3, Iteration 170, loss = 0.3525747\n",
      "Epoch 3, Iteration 180, loss = 0.2480283\n",
      "Epoch 3, Iteration 190, loss = 0.2241628\n",
      "Epoch 3, Iteration 200, loss = 0.0516268\n",
      "Epoch 3, Iteration 210, loss = 0.1613046\n",
      "Epoch 3, Iteration 220, loss = 0.1548829\n",
      "Epoch 3, Iteration 230, loss = 0.0415290\n",
      "Got 181 / 347 correct (52.16)\n",
      "Epoch 4, Iteration 0, loss = 0.0617369\n",
      "Epoch 4, Iteration 10, loss = 0.2319868\n",
      "Epoch 4, Iteration 20, loss = 0.0224905\n",
      "Epoch 4, Iteration 30, loss = 0.1019318\n",
      "Epoch 4, Iteration 40, loss = 0.1040307\n",
      "Epoch 4, Iteration 50, loss = 0.0214656\n",
      "Epoch 4, Iteration 60, loss = 0.0981870\n",
      "Epoch 4, Iteration 70, loss = 0.1744121\n",
      "Epoch 4, Iteration 80, loss = 0.1145055\n",
      "Epoch 4, Iteration 90, loss = 0.1088498\n",
      "Epoch 4, Iteration 100, loss = 0.0645746\n",
      "Epoch 4, Iteration 110, loss = 0.2407608\n",
      "Epoch 4, Iteration 120, loss = 0.0936755\n",
      "Epoch 4, Iteration 130, loss = 0.1197357\n",
      "Epoch 4, Iteration 140, loss = 0.0487211\n",
      "Epoch 4, Iteration 150, loss = 0.0343846\n",
      "Epoch 4, Iteration 160, loss = 0.0253696\n",
      "Epoch 4, Iteration 170, loss = 0.0259266\n",
      "Epoch 4, Iteration 180, loss = 0.3267427\n",
      "Epoch 4, Iteration 190, loss = 0.3298518\n",
      "Epoch 4, Iteration 200, loss = 0.2662525\n",
      "Epoch 4, Iteration 210, loss = 0.0538836\n",
      "Epoch 4, Iteration 220, loss = 0.0228326\n",
      "Epoch 4, Iteration 230, loss = 0.1444035\n",
      "Got 160 / 347 correct (46.11)\n",
      "Epoch 5, Iteration 0, loss = 0.0284635\n",
      "Epoch 5, Iteration 10, loss = 0.0147261\n",
      "Epoch 5, Iteration 20, loss = 0.0269357\n",
      "Epoch 5, Iteration 30, loss = 0.0215162\n",
      "Epoch 5, Iteration 40, loss = 0.0013384\n",
      "Epoch 5, Iteration 50, loss = 0.0132152\n",
      "Epoch 5, Iteration 60, loss = 0.0007124\n",
      "Epoch 5, Iteration 70, loss = 0.1868339\n",
      "Epoch 5, Iteration 80, loss = 0.2995740\n",
      "Epoch 5, Iteration 90, loss = 0.2395487\n",
      "Epoch 5, Iteration 100, loss = 0.0841979\n",
      "Epoch 5, Iteration 110, loss = 0.2125416\n",
      "Epoch 5, Iteration 120, loss = 0.1142271\n",
      "Epoch 5, Iteration 130, loss = 0.0650301\n",
      "Epoch 5, Iteration 140, loss = 0.2023272\n",
      "Epoch 5, Iteration 150, loss = 0.0206874\n",
      "Epoch 5, Iteration 160, loss = 0.0740494\n",
      "Epoch 5, Iteration 170, loss = 0.0093976\n",
      "Epoch 5, Iteration 180, loss = 0.0363440\n",
      "Epoch 5, Iteration 190, loss = 0.0222867\n",
      "Epoch 5, Iteration 200, loss = 0.0752870\n",
      "Epoch 5, Iteration 210, loss = 0.0763171\n",
      "Epoch 5, Iteration 220, loss = 0.0110259\n",
      "Epoch 5, Iteration 230, loss = 0.0250867\n",
      "Got 198 / 347 correct (57.06)\n",
      "Epoch 6, Iteration 0, loss = 0.0098980\n",
      "Epoch 6, Iteration 10, loss = 0.0194579\n",
      "Epoch 6, Iteration 20, loss = 0.1129064\n",
      "Epoch 6, Iteration 30, loss = 0.1564527\n",
      "Epoch 6, Iteration 40, loss = 0.0943099\n",
      "Epoch 6, Iteration 50, loss = 0.1269405\n",
      "Epoch 6, Iteration 60, loss = 0.0139594\n",
      "Epoch 6, Iteration 70, loss = 0.0089589\n",
      "Epoch 6, Iteration 80, loss = 0.0073359\n",
      "Epoch 6, Iteration 90, loss = 0.0993572\n",
      "Epoch 6, Iteration 100, loss = 0.0160390\n",
      "Epoch 6, Iteration 110, loss = 0.3285480\n",
      "Epoch 6, Iteration 120, loss = 0.0471712\n",
      "Epoch 6, Iteration 130, loss = 0.0203368\n",
      "Epoch 6, Iteration 140, loss = 0.0213873\n",
      "Epoch 6, Iteration 150, loss = 0.0286546\n",
      "Epoch 6, Iteration 160, loss = 0.2462860\n",
      "Epoch 6, Iteration 170, loss = 0.0122182\n",
      "Epoch 6, Iteration 180, loss = 0.1084026\n",
      "Epoch 6, Iteration 190, loss = 0.0192134\n",
      "Epoch 6, Iteration 200, loss = 0.1637324\n",
      "Epoch 6, Iteration 210, loss = 0.0033743\n",
      "Epoch 6, Iteration 220, loss = 0.0021925\n",
      "Epoch 6, Iteration 230, loss = 0.0855116\n",
      "Got 234 / 347 correct (67.44)\n",
      "Epoch 7, Iteration 0, loss = 0.0552637\n",
      "Epoch 7, Iteration 10, loss = 0.0120514\n",
      "Epoch 7, Iteration 20, loss = 0.0313783\n",
      "Epoch 7, Iteration 30, loss = 0.0093718\n",
      "Epoch 7, Iteration 40, loss = 0.0260607\n",
      "Epoch 7, Iteration 50, loss = 0.1201190\n",
      "Epoch 7, Iteration 60, loss = 0.1923211\n",
      "Epoch 7, Iteration 70, loss = 0.0726423\n",
      "Epoch 7, Iteration 80, loss = 0.0587540\n",
      "Epoch 7, Iteration 90, loss = 0.0413054\n",
      "Epoch 7, Iteration 100, loss = 0.0301107\n",
      "Epoch 7, Iteration 110, loss = 0.0493502\n",
      "Epoch 7, Iteration 120, loss = 0.0017095\n",
      "Epoch 7, Iteration 130, loss = 0.0010775\n",
      "Epoch 7, Iteration 140, loss = 0.0934158\n",
      "Epoch 7, Iteration 150, loss = 0.0054487\n",
      "Epoch 7, Iteration 160, loss = 0.0064806\n",
      "Epoch 7, Iteration 170, loss = 0.0621770\n",
      "Epoch 7, Iteration 180, loss = 0.0009448\n",
      "Epoch 7, Iteration 190, loss = 0.0017794\n",
      "Epoch 7, Iteration 200, loss = 0.0378124\n",
      "Epoch 7, Iteration 210, loss = 0.0024019\n",
      "Epoch 7, Iteration 220, loss = 0.0053954\n",
      "Epoch 7, Iteration 230, loss = 0.0596893\n",
      "Got 216 / 347 correct (62.25)\n",
      "Epoch 8, Iteration 0, loss = 0.0017604\n",
      "Epoch 8, Iteration 10, loss = 0.0127657\n",
      "Epoch 8, Iteration 20, loss = 0.0004894\n",
      "Epoch 8, Iteration 30, loss = 0.0667521\n",
      "Epoch 8, Iteration 40, loss = 0.0068323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Iteration 50, loss = 0.0033371\n",
      "Epoch 8, Iteration 60, loss = 0.0636274\n",
      "Epoch 8, Iteration 70, loss = 0.0220171\n",
      "Epoch 8, Iteration 80, loss = 0.0057125\n",
      "Epoch 8, Iteration 90, loss = 0.2818625\n",
      "Epoch 8, Iteration 100, loss = 0.0528690\n",
      "Epoch 8, Iteration 110, loss = 0.0251231\n",
      "Epoch 8, Iteration 120, loss = 0.0840302\n",
      "Epoch 8, Iteration 130, loss = 0.2248790\n",
      "Epoch 8, Iteration 140, loss = 0.0264085\n",
      "Epoch 8, Iteration 150, loss = 0.0051067\n",
      "Epoch 8, Iteration 160, loss = 0.0137498\n",
      "Epoch 8, Iteration 170, loss = 0.0358226\n",
      "Epoch 8, Iteration 180, loss = 0.0001674\n",
      "Epoch 8, Iteration 190, loss = 0.0068601\n",
      "Epoch 8, Iteration 200, loss = 0.0035950\n",
      "Epoch 8, Iteration 210, loss = 0.0376835\n",
      "Epoch 8, Iteration 220, loss = 0.0101020\n",
      "Epoch 8, Iteration 230, loss = 0.3592294\n",
      "Got 217 / 347 correct (62.54)\n",
      "Epoch 9, Iteration 0, loss = 0.0126276\n",
      "Epoch 9, Iteration 10, loss = 0.0014852\n",
      "Epoch 9, Iteration 20, loss = 0.0294608\n",
      "Epoch 9, Iteration 30, loss = 0.0056264\n",
      "Epoch 9, Iteration 40, loss = 0.0039830\n",
      "Epoch 9, Iteration 50, loss = 0.0970490\n",
      "Epoch 9, Iteration 60, loss = 0.0011904\n",
      "Epoch 9, Iteration 70, loss = 0.0008197\n",
      "Epoch 9, Iteration 80, loss = 0.0062342\n",
      "Epoch 9, Iteration 90, loss = 0.0258434\n",
      "Epoch 9, Iteration 100, loss = 0.0088010\n",
      "Epoch 9, Iteration 110, loss = 0.3216367\n",
      "Epoch 9, Iteration 120, loss = 0.0657514\n",
      "Epoch 9, Iteration 130, loss = 0.1409463\n",
      "Epoch 9, Iteration 140, loss = 0.0005922\n",
      "Epoch 9, Iteration 150, loss = 0.0023174\n",
      "Epoch 9, Iteration 160, loss = 0.0000252\n",
      "Epoch 9, Iteration 170, loss = 0.0068905\n",
      "Epoch 9, Iteration 180, loss = 0.0010825\n",
      "Epoch 9, Iteration 190, loss = 0.0115367\n",
      "Epoch 9, Iteration 200, loss = 0.0013058\n",
      "Epoch 9, Iteration 210, loss = 0.0000436\n",
      "Epoch 9, Iteration 220, loss = 0.0032405\n",
      "Epoch 9, Iteration 230, loss = 0.0212073\n",
      "Got 230 / 347 correct (66.28)\n",
      "Epoch 10, Iteration 0, loss = 0.0466486\n",
      "Epoch 10, Iteration 10, loss = 0.0000563\n",
      "Epoch 10, Iteration 20, loss = 0.0032730\n",
      "Epoch 10, Iteration 30, loss = 0.0010295\n",
      "Epoch 10, Iteration 40, loss = 0.0001676\n",
      "Epoch 10, Iteration 50, loss = 0.0529861\n",
      "Epoch 10, Iteration 60, loss = 0.0236520\n",
      "Epoch 10, Iteration 70, loss = 0.0011606\n",
      "Epoch 10, Iteration 80, loss = 0.0091558\n",
      "Epoch 10, Iteration 90, loss = 0.0001245\n",
      "Epoch 10, Iteration 100, loss = 0.0010051\n",
      "Epoch 10, Iteration 110, loss = 0.1553851\n",
      "Epoch 10, Iteration 120, loss = 0.0001555\n",
      "Epoch 10, Iteration 130, loss = 0.2043177\n",
      "Epoch 10, Iteration 140, loss = 0.0066158\n",
      "Epoch 10, Iteration 150, loss = 0.0002176\n",
      "Epoch 10, Iteration 160, loss = 0.0029928\n",
      "Epoch 10, Iteration 170, loss = 0.0016274\n",
      "Epoch 10, Iteration 180, loss = 0.0000320\n",
      "Epoch 10, Iteration 190, loss = 0.0024045\n",
      "Epoch 10, Iteration 200, loss = 0.0215873\n",
      "Epoch 10, Iteration 210, loss = 0.0013802\n",
      "Epoch 10, Iteration 220, loss = 0.0017044\n",
      "Epoch 10, Iteration 230, loss = 0.0048412\n",
      "Got 236 / 347 correct (68.01)\n",
      "Epoch 11, Iteration 0, loss = 0.0002368\n",
      "Epoch 11, Iteration 10, loss = 0.5697393\n",
      "Epoch 11, Iteration 20, loss = 0.0067112\n",
      "Epoch 11, Iteration 30, loss = 0.0048254\n",
      "Epoch 11, Iteration 40, loss = 0.0122017\n",
      "Epoch 11, Iteration 50, loss = 0.0059980\n",
      "Epoch 11, Iteration 60, loss = 0.0007095\n",
      "Epoch 11, Iteration 70, loss = 0.0009160\n",
      "Epoch 11, Iteration 80, loss = 0.0001306\n",
      "Epoch 11, Iteration 90, loss = 0.0011164\n",
      "Epoch 11, Iteration 100, loss = 0.0157164\n",
      "Epoch 11, Iteration 110, loss = 0.0054733\n",
      "Epoch 11, Iteration 120, loss = 0.0019789\n",
      "Epoch 11, Iteration 130, loss = 0.0343692\n",
      "Epoch 11, Iteration 140, loss = 0.1764314\n",
      "Epoch 11, Iteration 150, loss = 0.3857017\n",
      "Epoch 11, Iteration 160, loss = 0.0029176\n",
      "Epoch 11, Iteration 170, loss = 0.0073782\n",
      "Epoch 11, Iteration 180, loss = 0.0474879\n",
      "Epoch 11, Iteration 190, loss = 0.0080201\n",
      "Epoch 11, Iteration 200, loss = 0.0972367\n",
      "Epoch 11, Iteration 210, loss = 0.0087596\n",
      "Epoch 11, Iteration 220, loss = 0.0012094\n",
      "Epoch 11, Iteration 230, loss = 0.1657190\n",
      "Got 201 / 347 correct (57.93)\n",
      "Epoch 12, Iteration 0, loss = 0.0238487\n",
      "Epoch 12, Iteration 10, loss = 0.0388075\n",
      "Epoch 12, Iteration 20, loss = 0.2636193\n",
      "Epoch 12, Iteration 30, loss = 0.0436727\n",
      "Epoch 12, Iteration 40, loss = 0.2039443\n",
      "Epoch 12, Iteration 50, loss = 0.0131539\n",
      "Epoch 12, Iteration 60, loss = 0.0010353\n",
      "Epoch 12, Iteration 70, loss = 0.0012968\n",
      "Epoch 12, Iteration 80, loss = 0.0555807\n",
      "Epoch 12, Iteration 90, loss = 0.0041699\n",
      "Epoch 12, Iteration 100, loss = 0.0062313\n",
      "Epoch 12, Iteration 110, loss = 0.0165541\n",
      "Epoch 12, Iteration 120, loss = 0.0078067\n",
      "Epoch 12, Iteration 130, loss = 0.2096353\n",
      "Epoch 12, Iteration 140, loss = 0.0183560\n",
      "Epoch 12, Iteration 150, loss = 0.0025226\n",
      "Epoch 12, Iteration 160, loss = 0.0208492\n",
      "Epoch 12, Iteration 170, loss = 0.0458854\n",
      "Epoch 12, Iteration 180, loss = 0.0030119\n",
      "Epoch 12, Iteration 190, loss = 0.0008899\n",
      "Epoch 12, Iteration 200, loss = 0.0044202\n",
      "Epoch 12, Iteration 210, loss = 0.0039763\n",
      "Epoch 12, Iteration 220, loss = 0.0006950\n",
      "Epoch 12, Iteration 230, loss = 0.0040202\n",
      "Got 236 / 347 correct (68.01)\n",
      "Epoch 13, Iteration 0, loss = 0.0004234\n",
      "Epoch 13, Iteration 10, loss = 0.0002219\n",
      "Epoch 13, Iteration 20, loss = 0.0122098\n",
      "Epoch 13, Iteration 30, loss = 0.0003541\n",
      "Epoch 13, Iteration 40, loss = 0.0003761\n",
      "Epoch 13, Iteration 50, loss = 0.0012581\n",
      "Epoch 13, Iteration 60, loss = 0.2247471\n",
      "Epoch 13, Iteration 70, loss = 0.1205956\n",
      "Epoch 13, Iteration 80, loss = 0.0048660\n",
      "Epoch 13, Iteration 90, loss = 0.2062997\n",
      "Epoch 13, Iteration 100, loss = 0.0073360\n",
      "Epoch 13, Iteration 110, loss = 0.0505236\n",
      "Epoch 13, Iteration 120, loss = 0.0021549\n",
      "Epoch 13, Iteration 130, loss = 0.0014266\n",
      "Epoch 13, Iteration 140, loss = 0.0132626\n",
      "Epoch 13, Iteration 150, loss = 0.0011681\n",
      "Epoch 13, Iteration 160, loss = 0.0028188\n",
      "Epoch 13, Iteration 170, loss = 0.0011732\n",
      "Epoch 13, Iteration 180, loss = 0.0000418\n",
      "Epoch 13, Iteration 190, loss = 0.0055518\n",
      "Epoch 13, Iteration 200, loss = 0.0010784\n",
      "Epoch 13, Iteration 210, loss = 0.0025992\n",
      "Epoch 13, Iteration 220, loss = 0.0001715\n",
      "Epoch 13, Iteration 230, loss = 0.0001373\n",
      "Got 198 / 347 correct (57.06)\n",
      "Epoch 14, Iteration 0, loss = 0.0030824\n",
      "Epoch 14, Iteration 10, loss = 0.0017526\n",
      "Epoch 14, Iteration 20, loss = 0.0009381\n",
      "Epoch 14, Iteration 30, loss = 0.0015441\n",
      "Epoch 14, Iteration 40, loss = 0.0008761\n",
      "Epoch 14, Iteration 50, loss = 0.0054181\n",
      "Epoch 14, Iteration 60, loss = 0.0045495\n",
      "Epoch 14, Iteration 70, loss = 0.0009927\n",
      "Epoch 14, Iteration 80, loss = 0.0012090\n",
      "Epoch 14, Iteration 90, loss = 0.0001616\n",
      "Epoch 14, Iteration 100, loss = 0.0018467\n",
      "Epoch 14, Iteration 110, loss = 0.0020111\n",
      "Epoch 14, Iteration 120, loss = 0.0013180\n",
      "Epoch 14, Iteration 130, loss = 0.0998301\n",
      "Epoch 14, Iteration 140, loss = 0.0208737\n",
      "Epoch 14, Iteration 150, loss = 0.0000075\n",
      "Epoch 14, Iteration 160, loss = 0.0889402\n",
      "Epoch 14, Iteration 170, loss = 0.0017754\n",
      "Epoch 14, Iteration 180, loss = 0.0006737\n",
      "Epoch 14, Iteration 190, loss = 0.0000659\n",
      "Epoch 14, Iteration 200, loss = 0.0034122\n",
      "Epoch 14, Iteration 210, loss = 0.0009774\n",
      "Epoch 14, Iteration 220, loss = 0.0003218\n",
      "Epoch 14, Iteration 230, loss = 0.0018518\n",
      "Got 216 / 347 correct (62.25)\n",
      "Epoch 15, Iteration 0, loss = 0.0005169\n",
      "Epoch 15, Iteration 10, loss = 0.0037179\n",
      "Epoch 15, Iteration 20, loss = 0.0009077\n",
      "Epoch 15, Iteration 30, loss = 0.0000476\n",
      "Epoch 15, Iteration 40, loss = 0.0012810\n",
      "Epoch 15, Iteration 50, loss = 0.0093599\n",
      "Epoch 15, Iteration 60, loss = 0.3732098\n",
      "Epoch 15, Iteration 70, loss = 0.0034940\n",
      "Epoch 15, Iteration 80, loss = 0.0016750\n",
      "Epoch 15, Iteration 90, loss = 0.0022745\n",
      "Epoch 15, Iteration 100, loss = 0.0002613\n",
      "Epoch 15, Iteration 110, loss = 0.0013625\n",
      "Epoch 15, Iteration 120, loss = 0.0238743\n",
      "Epoch 15, Iteration 130, loss = 0.0000630\n",
      "Epoch 15, Iteration 140, loss = 0.0022600\n",
      "Epoch 15, Iteration 150, loss = 0.0308161\n",
      "Epoch 15, Iteration 160, loss = 0.1388639\n",
      "Epoch 15, Iteration 170, loss = 0.0078030\n",
      "Epoch 15, Iteration 180, loss = 0.0072085\n",
      "Epoch 15, Iteration 190, loss = 0.0162013\n",
      "Epoch 15, Iteration 200, loss = 0.0561900\n",
      "Epoch 15, Iteration 210, loss = 0.0148411\n",
      "Epoch 15, Iteration 220, loss = 0.0220669\n",
      "Epoch 15, Iteration 230, loss = 0.3837072\n",
      "Got 120 / 347 correct (34.58)\n",
      "Epoch 16, Iteration 0, loss = 0.0048355\n",
      "Epoch 16, Iteration 10, loss = 0.2115467\n",
      "Epoch 16, Iteration 20, loss = 0.2848784\n",
      "Epoch 16, Iteration 30, loss = 0.0116011\n",
      "Epoch 16, Iteration 40, loss = 0.0202341\n",
      "Epoch 16, Iteration 50, loss = 0.0280417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Iteration 60, loss = 0.0073223\n",
      "Epoch 16, Iteration 70, loss = 0.0024760\n",
      "Epoch 16, Iteration 80, loss = 0.0327817\n",
      "Epoch 16, Iteration 90, loss = 0.0025899\n",
      "Epoch 16, Iteration 100, loss = 0.0032107\n",
      "Epoch 16, Iteration 110, loss = 0.0030205\n",
      "Epoch 16, Iteration 120, loss = 0.0010625\n",
      "Epoch 16, Iteration 130, loss = 0.0034216\n",
      "Epoch 16, Iteration 140, loss = 0.0043703\n",
      "Epoch 16, Iteration 150, loss = 0.1172629\n",
      "Epoch 16, Iteration 160, loss = 0.0000869\n",
      "Epoch 16, Iteration 170, loss = 0.0008754\n",
      "Epoch 16, Iteration 180, loss = 0.0002728\n",
      "Epoch 16, Iteration 190, loss = 0.0174857\n",
      "Epoch 16, Iteration 200, loss = 0.0126333\n",
      "Epoch 16, Iteration 210, loss = 0.0218232\n",
      "Epoch 16, Iteration 220, loss = 0.0685553\n",
      "Epoch 16, Iteration 230, loss = 0.0504613\n",
      "Got 226 / 347 correct (65.13)\n",
      "Epoch 17, Iteration 0, loss = 0.0000377\n",
      "Epoch 17, Iteration 10, loss = 0.0103486\n",
      "Epoch 17, Iteration 20, loss = 0.0000120\n",
      "Epoch 17, Iteration 30, loss = 0.0114880\n",
      "Epoch 17, Iteration 40, loss = 0.0003147\n",
      "Epoch 17, Iteration 50, loss = 0.0000648\n",
      "Epoch 17, Iteration 60, loss = 0.0008297\n",
      "Epoch 17, Iteration 70, loss = 0.0001372\n",
      "Epoch 17, Iteration 80, loss = 0.0006752\n",
      "Epoch 17, Iteration 90, loss = 0.0007896\n",
      "Epoch 17, Iteration 100, loss = 0.0033421\n",
      "Epoch 17, Iteration 110, loss = 0.0005861\n",
      "Epoch 17, Iteration 120, loss = 0.0888293\n",
      "Epoch 17, Iteration 130, loss = 0.5531443\n",
      "Epoch 17, Iteration 140, loss = 0.0176359\n",
      "Epoch 17, Iteration 150, loss = 0.0002956\n",
      "Epoch 17, Iteration 160, loss = 0.0003981\n",
      "Epoch 17, Iteration 170, loss = 0.0011948\n",
      "Epoch 17, Iteration 180, loss = 0.0016615\n",
      "Epoch 17, Iteration 190, loss = 0.0007268\n",
      "Epoch 17, Iteration 200, loss = 0.1424531\n",
      "Epoch 17, Iteration 210, loss = 0.1356823\n",
      "Epoch 17, Iteration 220, loss = 0.0150093\n",
      "Epoch 17, Iteration 230, loss = 0.0009122\n",
      "Got 201 / 347 correct (57.93)\n",
      "Epoch 18, Iteration 0, loss = 0.0097417\n",
      "Epoch 18, Iteration 10, loss = 0.0024009\n",
      "Epoch 18, Iteration 20, loss = 0.0003089\n",
      "Epoch 18, Iteration 30, loss = 0.0020364\n",
      "Epoch 18, Iteration 40, loss = 0.0002550\n",
      "Epoch 18, Iteration 50, loss = 0.0532666\n",
      "Epoch 18, Iteration 60, loss = 0.0026242\n",
      "Epoch 18, Iteration 70, loss = 0.0000281\n",
      "Epoch 18, Iteration 80, loss = 0.0001200\n",
      "Epoch 18, Iteration 90, loss = 0.0036323\n",
      "Epoch 18, Iteration 100, loss = 0.0298122\n",
      "Epoch 18, Iteration 110, loss = 0.0110115\n",
      "Epoch 18, Iteration 120, loss = 0.0005972\n",
      "Epoch 18, Iteration 130, loss = 0.0001121\n",
      "Epoch 18, Iteration 140, loss = 0.0000908\n",
      "Epoch 18, Iteration 150, loss = 0.0076549\n",
      "Epoch 18, Iteration 160, loss = 0.0002518\n",
      "Epoch 18, Iteration 170, loss = 0.0021515\n",
      "Epoch 18, Iteration 180, loss = 0.0010760\n",
      "Epoch 18, Iteration 190, loss = 0.0002543\n",
      "Epoch 18, Iteration 200, loss = 0.0016525\n",
      "Epoch 18, Iteration 210, loss = 0.0005617\n",
      "Epoch 18, Iteration 220, loss = 0.0022124\n",
      "Epoch 18, Iteration 230, loss = 0.0000206\n",
      "Got 200 / 347 correct (57.64)\n",
      "Epoch 19, Iteration 0, loss = 0.0000263\n",
      "Epoch 19, Iteration 10, loss = 0.0075748\n",
      "Epoch 19, Iteration 20, loss = 0.0005935\n",
      "Epoch 19, Iteration 30, loss = 0.0000282\n",
      "Epoch 19, Iteration 40, loss = 0.0197294\n",
      "Epoch 19, Iteration 50, loss = 0.0003258\n",
      "Epoch 19, Iteration 60, loss = 0.0001504\n",
      "Epoch 19, Iteration 70, loss = 0.0006531\n",
      "Epoch 19, Iteration 80, loss = 0.0002477\n",
      "Epoch 19, Iteration 90, loss = 0.0029791\n",
      "Epoch 19, Iteration 100, loss = 0.0005178\n",
      "Epoch 19, Iteration 110, loss = 0.0000277\n",
      "Epoch 19, Iteration 120, loss = 0.2957383\n",
      "Epoch 19, Iteration 130, loss = 0.0001320\n",
      "Epoch 19, Iteration 140, loss = 0.0002463\n",
      "Epoch 19, Iteration 150, loss = 0.0004185\n",
      "Epoch 19, Iteration 160, loss = 0.0000830\n",
      "Epoch 19, Iteration 170, loss = 0.0020583\n",
      "Epoch 19, Iteration 180, loss = 0.0044106\n",
      "Epoch 19, Iteration 190, loss = 0.0785317\n",
      "Epoch 19, Iteration 200, loss = 0.0021166\n",
      "Epoch 19, Iteration 210, loss = 0.0002747\n",
      "Epoch 19, Iteration 220, loss = 0.0000325\n",
      "Epoch 19, Iteration 230, loss = 0.0000708\n",
      "Got 230 / 347 correct (66.28)\n",
      "Epoch 20, Iteration 0, loss = 0.0002722\n",
      "Epoch 20, Iteration 10, loss = 0.0011514\n",
      "Epoch 20, Iteration 20, loss = 0.0018764\n",
      "Epoch 20, Iteration 30, loss = 0.0001943\n",
      "Epoch 20, Iteration 40, loss = 0.0011132\n",
      "Epoch 20, Iteration 50, loss = 0.0008968\n",
      "Epoch 20, Iteration 60, loss = 0.0005994\n",
      "Epoch 20, Iteration 70, loss = 0.0001397\n",
      "Epoch 20, Iteration 80, loss = 0.0063139\n",
      "Epoch 20, Iteration 90, loss = 0.0000016\n",
      "Epoch 20, Iteration 100, loss = 0.0158061\n",
      "Epoch 20, Iteration 110, loss = 0.0001611\n",
      "Epoch 20, Iteration 120, loss = 0.1703013\n",
      "Epoch 20, Iteration 130, loss = 0.0060609\n",
      "Epoch 20, Iteration 140, loss = 0.0003768\n",
      "Epoch 20, Iteration 150, loss = 0.0029981\n",
      "Epoch 20, Iteration 160, loss = 0.0046063\n",
      "Epoch 20, Iteration 170, loss = 0.0006978\n",
      "Epoch 20, Iteration 180, loss = 0.0006507\n",
      "Epoch 20, Iteration 190, loss = 0.0000227\n",
      "Epoch 20, Iteration 200, loss = 0.0005111\n",
      "Epoch 20, Iteration 210, loss = 0.0001883\n",
      "Epoch 20, Iteration 220, loss = 0.0001093\n",
      "Epoch 20, Iteration 230, loss = 0.0000877\n",
      "Got 245 / 347 correct (70.61)\n",
      "Epoch 21, Iteration 0, loss = 0.0771404\n",
      "Epoch 21, Iteration 10, loss = 0.0000419\n",
      "Epoch 21, Iteration 20, loss = 0.0001215\n",
      "Epoch 21, Iteration 30, loss = 0.0009637\n",
      "Epoch 21, Iteration 40, loss = 0.0712174\n",
      "Epoch 21, Iteration 50, loss = 0.1096563\n",
      "Epoch 21, Iteration 60, loss = 0.2567829\n",
      "Epoch 21, Iteration 70, loss = 0.0005155\n",
      "Epoch 21, Iteration 80, loss = 0.0240278\n",
      "Epoch 21, Iteration 90, loss = 0.0048910\n",
      "Epoch 21, Iteration 100, loss = 0.0039746\n",
      "Epoch 21, Iteration 110, loss = 0.0000378\n",
      "Epoch 21, Iteration 120, loss = 0.0975691\n",
      "Epoch 21, Iteration 130, loss = 0.0840417\n",
      "Epoch 21, Iteration 140, loss = 0.0002795\n",
      "Epoch 21, Iteration 150, loss = 0.0924662\n",
      "Epoch 21, Iteration 160, loss = 0.0043002\n",
      "Epoch 21, Iteration 170, loss = 0.0267752\n",
      "Epoch 21, Iteration 180, loss = 0.0574105\n",
      "Epoch 21, Iteration 190, loss = 0.0133369\n",
      "Epoch 21, Iteration 200, loss = 0.0051910\n",
      "Epoch 21, Iteration 210, loss = 0.0829359\n",
      "Epoch 21, Iteration 220, loss = 0.0039104\n",
      "Epoch 21, Iteration 230, loss = 0.1181394\n",
      "Got 240 / 347 correct (69.16)\n",
      "Epoch 22, Iteration 0, loss = 0.0035870\n",
      "Epoch 22, Iteration 10, loss = 0.0060455\n",
      "Epoch 22, Iteration 20, loss = 0.0012282\n",
      "Epoch 22, Iteration 30, loss = 0.0000044\n",
      "Epoch 22, Iteration 40, loss = 0.0067483\n",
      "Epoch 22, Iteration 50, loss = 0.0183941\n",
      "Epoch 22, Iteration 60, loss = 0.0110220\n",
      "Epoch 22, Iteration 70, loss = 0.0065079\n",
      "Epoch 22, Iteration 80, loss = 0.0012767\n",
      "Epoch 22, Iteration 90, loss = 0.0065871\n",
      "Epoch 22, Iteration 100, loss = 0.0022803\n",
      "Epoch 22, Iteration 110, loss = 0.0233393\n",
      "Epoch 22, Iteration 120, loss = 0.0029813\n",
      "Epoch 22, Iteration 130, loss = 0.0146658\n",
      "Epoch 22, Iteration 140, loss = 0.0001096\n",
      "Epoch 22, Iteration 150, loss = 0.0012027\n",
      "Epoch 22, Iteration 160, loss = 0.0047103\n",
      "Epoch 22, Iteration 170, loss = 0.0056036\n",
      "Epoch 22, Iteration 180, loss = 0.0001909\n",
      "Epoch 22, Iteration 190, loss = 0.0000077\n",
      "Epoch 22, Iteration 200, loss = 0.0003491\n",
      "Epoch 22, Iteration 210, loss = 0.0250972\n",
      "Epoch 22, Iteration 220, loss = 0.0001503\n",
      "Epoch 22, Iteration 230, loss = 0.0422641\n",
      "Got 244 / 347 correct (70.32)\n",
      "Epoch 23, Iteration 0, loss = 0.0011955\n",
      "Epoch 23, Iteration 10, loss = 0.0094357\n",
      "Epoch 23, Iteration 20, loss = 0.0233414\n",
      "Epoch 23, Iteration 30, loss = 0.0013304\n",
      "Epoch 23, Iteration 40, loss = 0.0007139\n",
      "Epoch 23, Iteration 50, loss = 0.0101170\n",
      "Epoch 23, Iteration 60, loss = 0.0023891\n",
      "Epoch 23, Iteration 70, loss = 0.0006700\n",
      "Epoch 23, Iteration 80, loss = 0.0009363\n",
      "Epoch 23, Iteration 90, loss = 0.0000515\n",
      "Epoch 23, Iteration 100, loss = 0.0025946\n",
      "Epoch 23, Iteration 110, loss = 0.0000107\n",
      "Epoch 23, Iteration 120, loss = 0.0006119\n",
      "Epoch 23, Iteration 130, loss = 0.0004181\n",
      "Epoch 23, Iteration 140, loss = 0.0000253\n",
      "Epoch 23, Iteration 150, loss = 0.0025968\n",
      "Epoch 23, Iteration 160, loss = 0.0726312\n",
      "Epoch 23, Iteration 170, loss = 0.0000040\n",
      "Epoch 23, Iteration 180, loss = 0.0472517\n",
      "Epoch 23, Iteration 190, loss = 0.0006715\n",
      "Epoch 23, Iteration 200, loss = 0.0089512\n",
      "Epoch 23, Iteration 210, loss = 0.0496757\n",
      "Epoch 23, Iteration 220, loss = 0.1307953\n",
      "Epoch 23, Iteration 230, loss = 0.5320333\n",
      "Got 234 / 347 correct (67.44)\n",
      "Epoch 24, Iteration 0, loss = 0.1550655\n",
      "Epoch 24, Iteration 10, loss = 0.0045490\n",
      "Epoch 24, Iteration 20, loss = 0.0112268\n",
      "Epoch 24, Iteration 30, loss = 0.0016586\n",
      "Epoch 24, Iteration 40, loss = 0.0026146\n",
      "Epoch 24, Iteration 50, loss = 0.0060960\n",
      "Epoch 24, Iteration 60, loss = 0.0108640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Iteration 70, loss = 0.0032366\n",
      "Epoch 24, Iteration 80, loss = 0.0125569\n",
      "Epoch 24, Iteration 90, loss = 0.0010010\n",
      "Epoch 24, Iteration 100, loss = 0.0010640\n",
      "Epoch 24, Iteration 110, loss = 0.0709203\n",
      "Epoch 24, Iteration 120, loss = 0.0000527\n",
      "Epoch 24, Iteration 130, loss = 0.0005155\n",
      "Epoch 24, Iteration 140, loss = 0.1793281\n",
      "Epoch 24, Iteration 150, loss = 0.0049488\n",
      "Epoch 24, Iteration 160, loss = 0.0000408\n",
      "Epoch 24, Iteration 170, loss = 0.0000242\n",
      "Epoch 24, Iteration 180, loss = 0.0001081\n",
      "Epoch 24, Iteration 190, loss = 0.4792520\n",
      "Epoch 24, Iteration 200, loss = 0.0006891\n",
      "Epoch 24, Iteration 210, loss = 0.0004752\n",
      "Epoch 24, Iteration 220, loss = 0.0243728\n",
      "Epoch 24, Iteration 230, loss = 0.0001241\n",
      "Got 219 / 347 correct (63.11)\n",
      "Epoch 25, Iteration 0, loss = 0.0001076\n",
      "Epoch 25, Iteration 10, loss = 0.0058086\n",
      "Epoch 25, Iteration 20, loss = 0.0158452\n",
      "Epoch 25, Iteration 30, loss = 0.0005496\n",
      "Epoch 25, Iteration 40, loss = 0.0003225\n",
      "Epoch 25, Iteration 50, loss = 0.0025862\n",
      "Epoch 25, Iteration 60, loss = 0.0001633\n",
      "Epoch 25, Iteration 70, loss = 0.0041126\n",
      "Epoch 25, Iteration 80, loss = 0.0053641\n",
      "Epoch 25, Iteration 90, loss = 0.0014629\n",
      "Epoch 25, Iteration 100, loss = 0.0106275\n",
      "Epoch 25, Iteration 110, loss = 0.0000779\n",
      "Epoch 25, Iteration 120, loss = 0.0000849\n",
      "Epoch 25, Iteration 130, loss = 0.0044407\n",
      "Epoch 25, Iteration 140, loss = 0.0001086\n",
      "Epoch 25, Iteration 150, loss = 0.0034750\n",
      "Epoch 25, Iteration 160, loss = 0.0000362\n",
      "Epoch 25, Iteration 170, loss = 0.0003211\n",
      "Epoch 25, Iteration 180, loss = 0.0000003\n",
      "Epoch 25, Iteration 190, loss = 0.0009772\n",
      "Epoch 25, Iteration 200, loss = 0.0004095\n",
      "Epoch 25, Iteration 210, loss = 0.0000115\n",
      "Epoch 25, Iteration 220, loss = 0.0000002\n",
      "Epoch 25, Iteration 230, loss = 0.0000369\n",
      "Got 239 / 347 correct (68.88)\n",
      "Epoch 26, Iteration 0, loss = 0.0004667\n",
      "Epoch 26, Iteration 10, loss = 0.0065842\n",
      "Epoch 26, Iteration 20, loss = 0.1592668\n",
      "Epoch 26, Iteration 30, loss = 0.0000264\n",
      "Epoch 26, Iteration 40, loss = 0.0003463\n",
      "Epoch 26, Iteration 50, loss = 0.0002285\n",
      "Epoch 26, Iteration 60, loss = 0.0094996\n",
      "Epoch 26, Iteration 70, loss = 0.0000754\n",
      "Epoch 26, Iteration 80, loss = 0.0000179\n",
      "Epoch 26, Iteration 90, loss = 0.0001937\n",
      "Epoch 26, Iteration 100, loss = 0.0000445\n",
      "Epoch 26, Iteration 110, loss = 0.0003468\n",
      "Epoch 26, Iteration 120, loss = 0.0002606\n",
      "Epoch 26, Iteration 130, loss = 0.0024378\n",
      "Epoch 26, Iteration 140, loss = 0.0031519\n",
      "Epoch 26, Iteration 150, loss = 0.0042824\n",
      "Epoch 26, Iteration 160, loss = 0.0004291\n",
      "Epoch 26, Iteration 170, loss = 0.0000004\n",
      "Epoch 26, Iteration 180, loss = 0.0003523\n",
      "Epoch 26, Iteration 190, loss = 0.0751353\n",
      "Epoch 26, Iteration 200, loss = 0.0032101\n",
      "Epoch 26, Iteration 210, loss = 0.0003811\n",
      "Epoch 26, Iteration 220, loss = 0.0136368\n",
      "Epoch 26, Iteration 230, loss = 0.0000719\n",
      "Got 249 / 347 correct (71.76)\n",
      "Epoch 27, Iteration 0, loss = 0.0000008\n",
      "Epoch 27, Iteration 10, loss = 0.0405927\n",
      "Epoch 27, Iteration 20, loss = 0.0674445\n",
      "Epoch 27, Iteration 30, loss = 0.0003236\n",
      "Epoch 27, Iteration 40, loss = 0.0000065\n",
      "Epoch 27, Iteration 50, loss = 0.0000102\n",
      "Epoch 27, Iteration 60, loss = 0.0000164\n",
      "Epoch 27, Iteration 70, loss = 0.0000253\n",
      "Epoch 27, Iteration 80, loss = 0.0002093\n",
      "Epoch 27, Iteration 90, loss = 0.0019714\n",
      "Epoch 27, Iteration 100, loss = 0.0389824\n",
      "Epoch 27, Iteration 110, loss = 0.0000200\n",
      "Epoch 27, Iteration 120, loss = 0.0000033\n",
      "Epoch 27, Iteration 130, loss = 0.0000001\n",
      "Epoch 27, Iteration 140, loss = 0.0005244\n",
      "Epoch 27, Iteration 150, loss = 0.0000013\n",
      "Epoch 27, Iteration 160, loss = 0.0000018\n",
      "Epoch 27, Iteration 170, loss = 0.0000319\n",
      "Epoch 27, Iteration 180, loss = 0.0000117\n",
      "Epoch 27, Iteration 190, loss = 0.0000808\n",
      "Epoch 27, Iteration 200, loss = 0.0000025\n",
      "Epoch 27, Iteration 210, loss = 0.0036319\n",
      "Epoch 27, Iteration 220, loss = 0.0000376\n",
      "Epoch 27, Iteration 230, loss = 0.0003564\n",
      "Got 179 / 347 correct (51.59)\n",
      "Epoch 28, Iteration 0, loss = 0.0000459\n",
      "Epoch 28, Iteration 10, loss = 0.0000121\n",
      "Epoch 28, Iteration 20, loss = 0.0000535\n",
      "Epoch 28, Iteration 30, loss = 0.0017012\n",
      "Epoch 28, Iteration 40, loss = 0.2635236\n",
      "Epoch 28, Iteration 50, loss = 0.0101277\n",
      "Epoch 28, Iteration 60, loss = 0.0000050\n",
      "Epoch 28, Iteration 70, loss = 0.1554790\n",
      "Epoch 28, Iteration 80, loss = 0.0052562\n",
      "Epoch 28, Iteration 90, loss = 0.0005890\n",
      "Epoch 28, Iteration 100, loss = 0.0508721\n",
      "Epoch 28, Iteration 110, loss = 0.1121937\n",
      "Epoch 28, Iteration 120, loss = 0.0000172\n",
      "Epoch 28, Iteration 130, loss = 0.0000374\n",
      "Epoch 28, Iteration 140, loss = 0.0024492\n",
      "Epoch 28, Iteration 150, loss = 0.0142895\n",
      "Epoch 28, Iteration 160, loss = 0.0000345\n",
      "Epoch 28, Iteration 170, loss = 0.0001353\n",
      "Epoch 28, Iteration 180, loss = 0.0008174\n",
      "Epoch 28, Iteration 190, loss = 0.0003147\n",
      "Epoch 28, Iteration 200, loss = 0.0000858\n",
      "Epoch 28, Iteration 210, loss = 0.0028790\n",
      "Epoch 28, Iteration 220, loss = 0.0002832\n",
      "Epoch 28, Iteration 230, loss = 0.0000209\n",
      "Got 227 / 347 correct (65.42)\n",
      "Epoch 29, Iteration 0, loss = 0.0010057\n",
      "Epoch 29, Iteration 10, loss = 0.3173273\n",
      "Epoch 29, Iteration 20, loss = 0.3368118\n",
      "Epoch 29, Iteration 30, loss = 0.0000641\n",
      "Epoch 29, Iteration 40, loss = 0.0011634\n",
      "Epoch 29, Iteration 50, loss = 0.0042866\n",
      "Epoch 29, Iteration 60, loss = 0.0000915\n",
      "Epoch 29, Iteration 70, loss = 0.0007736\n",
      "Epoch 29, Iteration 80, loss = 0.0009816\n",
      "Epoch 29, Iteration 90, loss = 0.0000786\n",
      "Epoch 29, Iteration 100, loss = 0.0183286\n",
      "Epoch 29, Iteration 110, loss = 0.0061177\n",
      "Epoch 29, Iteration 120, loss = 0.0008269\n",
      "Epoch 29, Iteration 130, loss = 0.0046246\n",
      "Epoch 29, Iteration 140, loss = 0.0004658\n",
      "Epoch 29, Iteration 150, loss = 0.0003900\n",
      "Epoch 29, Iteration 160, loss = 0.1774500\n",
      "Epoch 29, Iteration 170, loss = 0.0025498\n",
      "Epoch 29, Iteration 180, loss = 0.1094615\n",
      "Epoch 29, Iteration 190, loss = 0.0001458\n",
      "Epoch 29, Iteration 200, loss = 0.0008787\n",
      "Epoch 29, Iteration 210, loss = 0.0003032\n",
      "Epoch 29, Iteration 220, loss = 0.0467469\n",
      "Epoch 29, Iteration 230, loss = 0.0000250\n",
      "Got 252 / 347 correct (72.62)\n",
      "Epoch 30, Iteration 0, loss = 0.0021271\n",
      "Epoch 30, Iteration 10, loss = 0.0000045\n",
      "Epoch 30, Iteration 20, loss = 0.0155203\n",
      "Epoch 30, Iteration 30, loss = 0.0000209\n",
      "Epoch 30, Iteration 40, loss = 0.0001951\n",
      "Epoch 30, Iteration 50, loss = 0.0022613\n",
      "Epoch 30, Iteration 60, loss = 0.0000075\n",
      "Epoch 30, Iteration 70, loss = 0.0002720\n",
      "Epoch 30, Iteration 80, loss = 0.0029709\n",
      "Epoch 30, Iteration 90, loss = 0.0000021\n",
      "Epoch 30, Iteration 100, loss = 0.0003309\n",
      "Epoch 30, Iteration 110, loss = 0.0000470\n",
      "Epoch 30, Iteration 120, loss = 0.0010494\n",
      "Epoch 30, Iteration 130, loss = 0.0002552\n",
      "Epoch 30, Iteration 140, loss = 0.0000007\n",
      "Epoch 30, Iteration 150, loss = 0.0000478\n",
      "Epoch 30, Iteration 160, loss = 0.0000370\n",
      "Epoch 30, Iteration 170, loss = 0.0000602\n",
      "Epoch 30, Iteration 180, loss = 0.0001263\n",
      "Epoch 30, Iteration 190, loss = 0.0000656\n",
      "Epoch 30, Iteration 200, loss = 0.0000292\n",
      "Epoch 30, Iteration 210, loss = 0.0118575\n",
      "Epoch 30, Iteration 220, loss = 0.0028966\n",
      "Epoch 30, Iteration 230, loss = 0.0000180\n",
      "Got 244 / 347 correct (70.32)\n",
      "Epoch 31, Iteration 0, loss = 0.0137168\n",
      "Epoch 31, Iteration 10, loss = 0.0000375\n",
      "Epoch 31, Iteration 20, loss = 0.0021702\n",
      "Epoch 31, Iteration 30, loss = 0.0000001\n",
      "Epoch 31, Iteration 40, loss = 0.0000023\n",
      "Epoch 31, Iteration 50, loss = 0.0000039\n",
      "Epoch 31, Iteration 60, loss = 0.0001673\n",
      "Epoch 31, Iteration 70, loss = 0.0024855\n",
      "Epoch 31, Iteration 80, loss = 0.0051914\n",
      "Epoch 31, Iteration 90, loss = 0.1810225\n",
      "Epoch 31, Iteration 100, loss = 0.0004086\n",
      "Epoch 31, Iteration 110, loss = 0.0004205\n",
      "Epoch 31, Iteration 120, loss = 0.0203579\n",
      "Epoch 31, Iteration 130, loss = 0.0000010\n",
      "Epoch 31, Iteration 140, loss = 0.0000998\n",
      "Epoch 31, Iteration 150, loss = 0.0000037\n",
      "Epoch 31, Iteration 160, loss = 0.2267938\n",
      "Epoch 31, Iteration 170, loss = 0.0004820\n",
      "Epoch 31, Iteration 180, loss = 0.0004173\n",
      "Epoch 31, Iteration 190, loss = 0.0047828\n",
      "Epoch 31, Iteration 200, loss = 0.1469212\n",
      "Epoch 31, Iteration 210, loss = 0.0291743\n",
      "Epoch 31, Iteration 220, loss = 0.0001026\n",
      "Epoch 31, Iteration 230, loss = 0.0042948\n",
      "Got 216 / 347 correct (62.25)\n",
      "Epoch 32, Iteration 0, loss = 0.0042358\n",
      "Epoch 32, Iteration 10, loss = 0.0158984\n",
      "Epoch 32, Iteration 20, loss = 0.0000021\n",
      "Epoch 32, Iteration 30, loss = 0.0001883\n",
      "Epoch 32, Iteration 40, loss = 0.0001361\n",
      "Epoch 32, Iteration 50, loss = 0.0001236\n",
      "Epoch 32, Iteration 60, loss = 0.0000070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Iteration 70, loss = 0.0000221\n",
      "Epoch 32, Iteration 80, loss = 0.0005711\n",
      "Epoch 32, Iteration 90, loss = 0.0000659\n",
      "Epoch 32, Iteration 100, loss = 0.1263027\n",
      "Epoch 32, Iteration 110, loss = 0.0021345\n",
      "Epoch 32, Iteration 120, loss = 0.0000358\n",
      "Epoch 32, Iteration 130, loss = 0.0000417\n",
      "Epoch 32, Iteration 140, loss = 0.0009649\n",
      "Epoch 32, Iteration 150, loss = 0.0000272\n",
      "Epoch 32, Iteration 160, loss = 0.0101088\n",
      "Epoch 32, Iteration 170, loss = 0.0006225\n",
      "Epoch 32, Iteration 180, loss = 0.0001307\n",
      "Epoch 32, Iteration 190, loss = 0.0027061\n",
      "Epoch 32, Iteration 200, loss = 0.0035648\n",
      "Epoch 32, Iteration 210, loss = 0.0000985\n",
      "Epoch 32, Iteration 220, loss = 0.0000377\n",
      "Epoch 32, Iteration 230, loss = 0.2272085\n",
      "Got 238 / 347 correct (68.59)\n",
      "Epoch 33, Iteration 0, loss = 0.0000736\n",
      "Epoch 33, Iteration 10, loss = 0.0004687\n",
      "Epoch 33, Iteration 20, loss = 0.2530938\n",
      "Epoch 33, Iteration 30, loss = 0.0691204\n",
      "Epoch 33, Iteration 40, loss = 0.0004034\n",
      "Epoch 33, Iteration 50, loss = 0.0001426\n",
      "Epoch 33, Iteration 60, loss = 0.0000029\n",
      "Epoch 33, Iteration 70, loss = 0.0000341\n",
      "Epoch 33, Iteration 80, loss = 0.0008561\n",
      "Epoch 33, Iteration 90, loss = 0.0000029\n",
      "Epoch 33, Iteration 100, loss = 0.0023660\n",
      "Epoch 33, Iteration 110, loss = 0.0002223\n",
      "Epoch 33, Iteration 120, loss = 0.0010440\n",
      "Epoch 33, Iteration 130, loss = 0.0010153\n",
      "Epoch 33, Iteration 140, loss = 0.0000253\n",
      "Epoch 33, Iteration 150, loss = 0.0000110\n",
      "Epoch 33, Iteration 160, loss = 0.1298969\n",
      "Epoch 33, Iteration 170, loss = 0.0032588\n",
      "Epoch 33, Iteration 180, loss = 0.0069264\n",
      "Epoch 33, Iteration 190, loss = 0.0000104\n",
      "Epoch 33, Iteration 200, loss = 0.0000250\n",
      "Epoch 33, Iteration 210, loss = 0.0000275\n",
      "Epoch 33, Iteration 220, loss = 0.0000892\n",
      "Epoch 33, Iteration 230, loss = 0.0029231\n",
      "Got 238 / 347 correct (68.59)\n",
      "Epoch 34, Iteration 0, loss = 0.0000031\n",
      "Epoch 34, Iteration 10, loss = 0.0001528\n",
      "Epoch 34, Iteration 20, loss = 0.0001645\n",
      "Epoch 34, Iteration 30, loss = 0.0000442\n",
      "Epoch 34, Iteration 40, loss = 0.0011538\n",
      "Epoch 34, Iteration 50, loss = 0.0000968\n",
      "Epoch 34, Iteration 60, loss = 0.0010091\n",
      "Epoch 34, Iteration 70, loss = 0.0001430\n",
      "Epoch 34, Iteration 80, loss = 0.0005583\n",
      "Epoch 34, Iteration 90, loss = 0.0003008\n",
      "Epoch 34, Iteration 100, loss = 0.0000789\n",
      "Epoch 34, Iteration 110, loss = 0.0001130\n",
      "Epoch 34, Iteration 120, loss = 0.0002792\n",
      "Epoch 34, Iteration 130, loss = 0.0001235\n",
      "Epoch 34, Iteration 140, loss = 0.0000012\n",
      "Epoch 34, Iteration 150, loss = 0.0003777\n",
      "Epoch 34, Iteration 160, loss = 0.0000761\n",
      "Epoch 34, Iteration 170, loss = 0.0003829\n",
      "Epoch 34, Iteration 180, loss = 0.0004681\n",
      "Epoch 34, Iteration 190, loss = 0.0000005\n",
      "Epoch 34, Iteration 200, loss = 0.0178471\n",
      "Epoch 34, Iteration 210, loss = 0.0000039\n",
      "Epoch 34, Iteration 220, loss = 0.0000056\n",
      "Epoch 34, Iteration 230, loss = 0.0002281\n",
      "Got 241 / 347 correct (69.45)\n",
      "Epoch 35, Iteration 0, loss = 0.0000648\n",
      "Epoch 35, Iteration 10, loss = 0.0000928\n",
      "Epoch 35, Iteration 20, loss = 0.0000099\n",
      "Epoch 35, Iteration 30, loss = 0.0002137\n",
      "Epoch 35, Iteration 40, loss = 0.0000002\n",
      "Epoch 35, Iteration 50, loss = 0.0001918\n",
      "Epoch 35, Iteration 60, loss = 0.0014218\n",
      "Epoch 35, Iteration 70, loss = 0.0003026\n",
      "Epoch 35, Iteration 80, loss = 0.0013233\n",
      "Epoch 35, Iteration 90, loss = 0.0000010\n",
      "Epoch 35, Iteration 100, loss = 0.0000225\n",
      "Epoch 35, Iteration 110, loss = 0.0000290\n",
      "Epoch 35, Iteration 120, loss = 0.0004742\n",
      "Epoch 35, Iteration 130, loss = 0.0000425\n",
      "Epoch 35, Iteration 140, loss = 0.0000043\n",
      "Epoch 35, Iteration 150, loss = 0.0014744\n",
      "Epoch 35, Iteration 160, loss = 0.0002154\n",
      "Epoch 35, Iteration 170, loss = 0.0000059\n",
      "Epoch 35, Iteration 180, loss = 0.0011694\n",
      "Epoch 35, Iteration 190, loss = 0.0000070\n",
      "Epoch 35, Iteration 200, loss = 0.0007720\n",
      "Epoch 35, Iteration 210, loss = 0.0001231\n",
      "Epoch 35, Iteration 220, loss = 0.0000062\n",
      "Epoch 35, Iteration 230, loss = 0.0016911\n",
      "Got 239 / 347 correct (68.88)\n",
      "Epoch 36, Iteration 0, loss = 0.0001839\n",
      "Epoch 36, Iteration 10, loss = 0.0000359\n",
      "Epoch 36, Iteration 20, loss = 0.0000207\n",
      "Epoch 36, Iteration 30, loss = 0.0027182\n",
      "Epoch 36, Iteration 40, loss = 0.0031541\n",
      "Epoch 36, Iteration 50, loss = 0.0020725\n",
      "Epoch 36, Iteration 60, loss = 0.0028832\n",
      "Epoch 36, Iteration 70, loss = 0.0002164\n",
      "Epoch 36, Iteration 80, loss = 0.0018843\n",
      "Epoch 36, Iteration 90, loss = 0.0067387\n",
      "Epoch 36, Iteration 100, loss = 0.0000018\n",
      "Epoch 36, Iteration 110, loss = 0.0070016\n",
      "Epoch 36, Iteration 120, loss = 0.0000489\n",
      "Epoch 36, Iteration 130, loss = 0.0000120\n",
      "Epoch 36, Iteration 140, loss = 0.0005345\n",
      "Epoch 36, Iteration 150, loss = 0.0357957\n",
      "Epoch 36, Iteration 160, loss = 0.0094653\n",
      "Epoch 36, Iteration 170, loss = 0.0003088\n",
      "Epoch 36, Iteration 180, loss = 0.0606571\n",
      "Epoch 36, Iteration 190, loss = 0.0001477\n",
      "Epoch 36, Iteration 200, loss = 0.0111944\n",
      "Epoch 36, Iteration 210, loss = 0.0002882\n",
      "Epoch 36, Iteration 220, loss = 0.0031561\n",
      "Epoch 36, Iteration 230, loss = 0.0020929\n",
      "Got 243 / 347 correct (70.03)\n",
      "Epoch 37, Iteration 0, loss = 0.0039610\n",
      "Epoch 37, Iteration 10, loss = 0.0001888\n",
      "Epoch 37, Iteration 20, loss = 0.0004322\n",
      "Epoch 37, Iteration 30, loss = 0.0319151\n",
      "Epoch 37, Iteration 40, loss = 0.0002377\n",
      "Epoch 37, Iteration 50, loss = 0.0000179\n",
      "Epoch 37, Iteration 60, loss = 0.0015395\n",
      "Epoch 37, Iteration 70, loss = 0.0000092\n",
      "Epoch 37, Iteration 80, loss = 0.0015094\n",
      "Epoch 37, Iteration 90, loss = 0.0074367\n",
      "Epoch 37, Iteration 100, loss = 0.0000187\n",
      "Epoch 37, Iteration 110, loss = 0.0037624\n",
      "Epoch 37, Iteration 120, loss = 0.0013454\n",
      "Epoch 37, Iteration 130, loss = 0.0000410\n",
      "Epoch 37, Iteration 140, loss = 0.0017920\n",
      "Epoch 37, Iteration 150, loss = 0.0001005\n",
      "Epoch 37, Iteration 160, loss = 0.0002164\n",
      "Epoch 37, Iteration 170, loss = 0.0342246\n",
      "Epoch 37, Iteration 180, loss = 0.0019073\n",
      "Epoch 37, Iteration 190, loss = 0.0083083\n",
      "Epoch 37, Iteration 200, loss = 0.0029514\n",
      "Epoch 37, Iteration 210, loss = 0.3802982\n",
      "Epoch 37, Iteration 220, loss = 0.0003089\n",
      "Epoch 37, Iteration 230, loss = 0.0029084\n",
      "Got 242 / 347 correct (69.74)\n",
      "Epoch 38, Iteration 0, loss = 0.0000058\n",
      "Epoch 38, Iteration 10, loss = 0.0000029\n",
      "Epoch 38, Iteration 20, loss = 0.0001073\n",
      "Epoch 38, Iteration 30, loss = 0.0000037\n",
      "Epoch 38, Iteration 40, loss = 0.0014850\n",
      "Epoch 38, Iteration 50, loss = 0.0005954\n",
      "Epoch 38, Iteration 60, loss = 0.0264411\n",
      "Epoch 38, Iteration 70, loss = 0.0000010\n",
      "Epoch 38, Iteration 80, loss = 0.0000009\n",
      "Epoch 38, Iteration 90, loss = 0.0536265\n",
      "Epoch 38, Iteration 100, loss = 0.0001151\n",
      "Epoch 38, Iteration 110, loss = 0.0036542\n",
      "Epoch 38, Iteration 120, loss = 0.0004867\n",
      "Epoch 38, Iteration 130, loss = 0.0001661\n",
      "Epoch 38, Iteration 140, loss = 0.0000184\n",
      "Epoch 38, Iteration 150, loss = 0.0000215\n",
      "Epoch 38, Iteration 160, loss = 0.0000048\n",
      "Epoch 38, Iteration 170, loss = 0.0002822\n",
      "Epoch 38, Iteration 180, loss = 0.0000194\n",
      "Epoch 38, Iteration 190, loss = 0.0013466\n",
      "Epoch 38, Iteration 200, loss = 0.0045457\n",
      "Epoch 38, Iteration 210, loss = 0.0000004\n",
      "Epoch 38, Iteration 220, loss = 0.0000002\n",
      "Epoch 38, Iteration 230, loss = 0.0000124\n",
      "Got 246 / 347 correct (70.89)\n",
      "Epoch 39, Iteration 0, loss = 0.0000523\n",
      "Epoch 39, Iteration 10, loss = 0.0000356\n",
      "Epoch 39, Iteration 20, loss = 0.0000002\n",
      "Epoch 39, Iteration 30, loss = 0.0000540\n",
      "Epoch 39, Iteration 40, loss = 0.0000002\n",
      "Epoch 39, Iteration 50, loss = 0.0000226\n",
      "Epoch 39, Iteration 60, loss = 0.0000017\n",
      "Epoch 39, Iteration 70, loss = 0.0000021\n",
      "Epoch 39, Iteration 80, loss = 0.0000000\n",
      "Epoch 39, Iteration 90, loss = 0.0000656\n",
      "Epoch 39, Iteration 100, loss = 0.0005077\n",
      "Epoch 39, Iteration 110, loss = 0.0000070\n",
      "Epoch 39, Iteration 120, loss = 0.0051581\n",
      "Epoch 39, Iteration 130, loss = 0.0013220\n",
      "Epoch 39, Iteration 140, loss = 0.1180232\n",
      "Epoch 39, Iteration 150, loss = 0.0003428\n",
      "Epoch 39, Iteration 160, loss = 0.0015210\n",
      "Epoch 39, Iteration 170, loss = 0.0037517\n",
      "Epoch 39, Iteration 180, loss = 0.0000827\n",
      "Epoch 39, Iteration 190, loss = 0.0003459\n",
      "Epoch 39, Iteration 200, loss = 0.0576735\n",
      "Epoch 39, Iteration 210, loss = 0.0077798\n",
      "Epoch 39, Iteration 220, loss = 0.0004207\n",
      "Epoch 39, Iteration 230, loss = 0.0004268\n",
      "Got 248 / 347 correct (71.47)\n",
      "Epoch 40, Iteration 0, loss = 0.0131064\n",
      "Epoch 40, Iteration 10, loss = 0.0005779\n",
      "Epoch 40, Iteration 20, loss = 0.0244485\n",
      "Epoch 40, Iteration 30, loss = 0.1230482\n",
      "Epoch 40, Iteration 40, loss = 0.0007544\n",
      "Epoch 40, Iteration 50, loss = 0.0000272\n",
      "Epoch 40, Iteration 60, loss = 0.0007623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Iteration 70, loss = 0.0065940\n",
      "Epoch 40, Iteration 80, loss = 0.0008583\n",
      "Epoch 40, Iteration 90, loss = 0.0006124\n",
      "Epoch 40, Iteration 100, loss = 0.0004014\n",
      "Epoch 40, Iteration 110, loss = 0.0004884\n",
      "Epoch 40, Iteration 120, loss = 0.0001043\n",
      "Epoch 40, Iteration 130, loss = 0.6666452\n",
      "Epoch 40, Iteration 140, loss = 0.0001007\n",
      "Epoch 40, Iteration 150, loss = 0.0004723\n",
      "Epoch 40, Iteration 160, loss = 0.0028708\n",
      "Epoch 40, Iteration 170, loss = 0.0000002\n",
      "Epoch 40, Iteration 180, loss = 0.0007447\n",
      "Epoch 40, Iteration 190, loss = 0.0008022\n",
      "Epoch 40, Iteration 200, loss = 0.0000966\n",
      "Epoch 40, Iteration 210, loss = 0.0000145\n",
      "Epoch 40, Iteration 220, loss = 0.0001300\n",
      "Epoch 40, Iteration 230, loss = 0.0000348\n",
      "Got 249 / 347 correct (71.76)\n",
      "Epoch 41, Iteration 0, loss = 0.0008223\n",
      "Epoch 41, Iteration 10, loss = 0.0001586\n",
      "Epoch 41, Iteration 20, loss = 0.0000671\n",
      "Epoch 41, Iteration 30, loss = 0.0210486\n",
      "Epoch 41, Iteration 40, loss = 0.0000006\n",
      "Epoch 41, Iteration 50, loss = 0.0000182\n",
      "Epoch 41, Iteration 60, loss = 0.0003197\n",
      "Epoch 41, Iteration 70, loss = 0.0000958\n",
      "Epoch 41, Iteration 80, loss = 0.0485361\n",
      "Epoch 41, Iteration 90, loss = 0.0000720\n",
      "Epoch 41, Iteration 100, loss = 0.0005489\n",
      "Epoch 41, Iteration 110, loss = 0.0001206\n",
      "Epoch 41, Iteration 120, loss = 0.0012112\n",
      "Epoch 41, Iteration 130, loss = 0.0000004\n",
      "Epoch 41, Iteration 140, loss = 0.0000215\n",
      "Epoch 41, Iteration 150, loss = 0.0000052\n",
      "Epoch 41, Iteration 160, loss = 0.0003958\n",
      "Epoch 41, Iteration 170, loss = 0.0002044\n",
      "Epoch 41, Iteration 180, loss = 0.0001332\n",
      "Epoch 41, Iteration 190, loss = 0.0000114\n",
      "Epoch 41, Iteration 200, loss = 0.0003551\n",
      "Epoch 41, Iteration 210, loss = 0.0059619\n",
      "Epoch 41, Iteration 220, loss = 0.3546618\n",
      "Epoch 41, Iteration 230, loss = 0.0000001\n",
      "Got 255 / 347 correct (73.49)\n",
      "Epoch 42, Iteration 0, loss = 0.0000096\n",
      "Epoch 42, Iteration 10, loss = 0.0001572\n",
      "Epoch 42, Iteration 20, loss = 0.0006429\n",
      "Epoch 42, Iteration 30, loss = 0.0000003\n",
      "Epoch 42, Iteration 40, loss = 0.1245080\n",
      "Epoch 42, Iteration 50, loss = 0.0000202\n",
      "Epoch 42, Iteration 60, loss = 0.0000091\n",
      "Epoch 42, Iteration 70, loss = 0.0001297\n",
      "Epoch 42, Iteration 80, loss = 0.0000056\n",
      "Epoch 42, Iteration 90, loss = 0.0000489\n",
      "Epoch 42, Iteration 100, loss = 0.0000038\n",
      "Epoch 42, Iteration 110, loss = 0.0000087\n",
      "Epoch 42, Iteration 120, loss = 0.0001626\n",
      "Epoch 42, Iteration 130, loss = 0.0044518\n",
      "Epoch 42, Iteration 140, loss = 0.0000000\n",
      "Epoch 42, Iteration 150, loss = 0.0000562\n",
      "Epoch 42, Iteration 160, loss = 0.3832007\n",
      "Epoch 42, Iteration 170, loss = 0.0000002\n",
      "Epoch 42, Iteration 180, loss = 0.0289859\n",
      "Epoch 42, Iteration 190, loss = 0.0000056\n",
      "Epoch 42, Iteration 200, loss = 0.0000088\n",
      "Epoch 42, Iteration 210, loss = 0.0000148\n",
      "Epoch 42, Iteration 220, loss = 0.0000015\n",
      "Epoch 42, Iteration 230, loss = 0.0122303\n",
      "Got 230 / 347 correct (66.28)\n",
      "Epoch 43, Iteration 0, loss = 0.0000570\n",
      "Epoch 43, Iteration 10, loss = 0.0000873\n",
      "Epoch 43, Iteration 20, loss = 0.0011044\n",
      "Epoch 43, Iteration 30, loss = 0.0002677\n",
      "Epoch 43, Iteration 40, loss = 0.0000145\n",
      "Epoch 43, Iteration 50, loss = 0.0200901\n",
      "Epoch 43, Iteration 60, loss = 0.0000114\n",
      "Epoch 43, Iteration 70, loss = 0.0158507\n",
      "Epoch 43, Iteration 80, loss = 0.0005405\n",
      "Epoch 43, Iteration 90, loss = 0.0000005\n",
      "Epoch 43, Iteration 100, loss = 0.0000331\n",
      "Epoch 43, Iteration 110, loss = 0.0011122\n",
      "Epoch 43, Iteration 120, loss = 0.0018490\n",
      "Epoch 43, Iteration 130, loss = 0.0004801\n",
      "Epoch 43, Iteration 140, loss = 0.0013696\n",
      "Epoch 43, Iteration 150, loss = 0.0000518\n",
      "Epoch 43, Iteration 160, loss = 0.0000079\n",
      "Epoch 43, Iteration 170, loss = 0.0000014\n",
      "Epoch 43, Iteration 180, loss = 0.0000001\n",
      "Epoch 43, Iteration 190, loss = 0.0000455\n",
      "Epoch 43, Iteration 200, loss = 0.0000156\n",
      "Epoch 43, Iteration 210, loss = 0.0004949\n",
      "Epoch 43, Iteration 220, loss = 0.0000461\n",
      "Epoch 43, Iteration 230, loss = 0.0000191\n",
      "Got 223 / 347 correct (64.27)\n",
      "Epoch 44, Iteration 0, loss = 0.0000118\n",
      "Epoch 44, Iteration 10, loss = 0.0015644\n",
      "Epoch 44, Iteration 20, loss = 0.0000559\n",
      "Epoch 44, Iteration 30, loss = 0.0028839\n",
      "Epoch 44, Iteration 40, loss = 0.0036021\n",
      "Epoch 44, Iteration 50, loss = 0.0000091\n",
      "Epoch 44, Iteration 60, loss = 0.0009902\n",
      "Epoch 44, Iteration 70, loss = 0.0083574\n",
      "Epoch 44, Iteration 80, loss = 0.0000354\n",
      "Epoch 44, Iteration 90, loss = 0.0000390\n",
      "Epoch 44, Iteration 100, loss = 0.0000732\n",
      "Epoch 44, Iteration 110, loss = 0.0001146\n",
      "Epoch 44, Iteration 120, loss = 0.0007223\n",
      "Epoch 44, Iteration 130, loss = 0.0000229\n",
      "Epoch 44, Iteration 140, loss = 0.0000661\n",
      "Epoch 44, Iteration 150, loss = 0.0008529\n",
      "Epoch 44, Iteration 160, loss = 0.0012475\n",
      "Epoch 44, Iteration 170, loss = 0.0106230\n",
      "Epoch 44, Iteration 180, loss = 0.0041107\n",
      "Epoch 44, Iteration 190, loss = 0.0000290\n",
      "Epoch 44, Iteration 200, loss = 0.0000163\n",
      "Epoch 44, Iteration 210, loss = 0.0000058\n",
      "Epoch 44, Iteration 220, loss = 0.0000389\n",
      "Epoch 44, Iteration 230, loss = 0.0000141\n",
      "Got 228 / 347 correct (65.71)\n",
      "Epoch 45, Iteration 0, loss = 0.0000468\n",
      "Epoch 45, Iteration 10, loss = 0.0000011\n",
      "Epoch 45, Iteration 20, loss = 0.0000000\n",
      "Epoch 45, Iteration 30, loss = 0.0001362\n",
      "Epoch 45, Iteration 40, loss = 0.0001837\n",
      "Epoch 45, Iteration 50, loss = 0.0000239\n",
      "Epoch 45, Iteration 60, loss = 0.0000011\n",
      "Epoch 45, Iteration 70, loss = 0.0000005\n",
      "Epoch 45, Iteration 80, loss = 0.0002484\n",
      "Epoch 45, Iteration 90, loss = 0.0001304\n",
      "Epoch 45, Iteration 100, loss = 0.0000038\n",
      "Epoch 45, Iteration 110, loss = 0.0007836\n",
      "Epoch 45, Iteration 120, loss = 0.0000660\n",
      "Epoch 45, Iteration 130, loss = 0.0000093\n",
      "Epoch 45, Iteration 140, loss = 0.0000008\n",
      "Epoch 45, Iteration 150, loss = 0.0000098\n",
      "Epoch 45, Iteration 160, loss = 0.0006386\n",
      "Epoch 45, Iteration 170, loss = 0.0000299\n",
      "Epoch 45, Iteration 180, loss = 0.0002007\n",
      "Epoch 45, Iteration 190, loss = 0.0000212\n",
      "Epoch 45, Iteration 200, loss = 0.0000002\n",
      "Epoch 45, Iteration 210, loss = 0.0000176\n",
      "Epoch 45, Iteration 220, loss = 0.0000060\n",
      "Epoch 45, Iteration 230, loss = 0.0000000\n",
      "Got 229 / 347 correct (65.99)\n",
      "Epoch 46, Iteration 0, loss = 0.0000028\n",
      "Epoch 46, Iteration 10, loss = 0.0000634\n",
      "Epoch 46, Iteration 20, loss = 0.0002662\n",
      "Epoch 46, Iteration 30, loss = 0.0000059\n",
      "Epoch 46, Iteration 40, loss = 0.0000004\n",
      "Epoch 46, Iteration 50, loss = 0.0000223\n",
      "Epoch 46, Iteration 60, loss = 0.0000050\n",
      "Epoch 46, Iteration 70, loss = 0.0000991\n",
      "Epoch 46, Iteration 80, loss = 0.0001079\n",
      "Epoch 46, Iteration 90, loss = 0.0000017\n",
      "Epoch 46, Iteration 100, loss = 0.0000201\n",
      "Epoch 46, Iteration 110, loss = 0.0000060\n",
      "Epoch 46, Iteration 120, loss = 0.0000416\n",
      "Epoch 46, Iteration 130, loss = 0.0000010\n",
      "Epoch 46, Iteration 140, loss = 0.1839653\n",
      "Epoch 46, Iteration 150, loss = 0.0000333\n",
      "Epoch 46, Iteration 160, loss = 0.0000127\n",
      "Epoch 46, Iteration 170, loss = 0.0045068\n",
      "Epoch 46, Iteration 180, loss = 0.0000008\n",
      "Epoch 46, Iteration 190, loss = 0.0000021\n",
      "Epoch 46, Iteration 200, loss = 0.0004473\n",
      "Epoch 46, Iteration 210, loss = 0.0000056\n",
      "Epoch 46, Iteration 220, loss = 0.0000098\n",
      "Epoch 46, Iteration 230, loss = 0.0000080\n",
      "Got 211 / 347 correct (60.81)\n",
      "Epoch 47, Iteration 0, loss = 0.0000604\n",
      "Epoch 47, Iteration 10, loss = 0.0000491\n",
      "Epoch 47, Iteration 20, loss = 0.0002165\n",
      "Epoch 47, Iteration 30, loss = 0.0000013\n",
      "Epoch 47, Iteration 40, loss = 0.0000198\n",
      "Epoch 47, Iteration 50, loss = 0.0000121\n",
      "Epoch 47, Iteration 60, loss = 0.0000197\n",
      "Epoch 47, Iteration 70, loss = 0.0002957\n",
      "Epoch 47, Iteration 80, loss = 0.0000013\n",
      "Epoch 47, Iteration 90, loss = 0.0002524\n",
      "Epoch 47, Iteration 100, loss = 0.5977913\n",
      "Epoch 47, Iteration 110, loss = 0.0662635\n",
      "Epoch 47, Iteration 120, loss = 0.0002827\n",
      "Epoch 47, Iteration 130, loss = 0.0057875\n",
      "Epoch 47, Iteration 140, loss = 0.0002952\n",
      "Epoch 47, Iteration 150, loss = 0.0007695\n",
      "Epoch 47, Iteration 160, loss = 0.0001384\n",
      "Epoch 47, Iteration 170, loss = 0.0015626\n",
      "Epoch 47, Iteration 180, loss = 0.0000097\n",
      "Epoch 47, Iteration 190, loss = 0.0112895\n",
      "Epoch 47, Iteration 200, loss = 0.0007881\n",
      "Epoch 47, Iteration 210, loss = 0.0875420\n",
      "Epoch 47, Iteration 220, loss = 0.0001353\n",
      "Epoch 47, Iteration 230, loss = 0.0047936\n",
      "Got 229 / 347 correct (65.99)\n",
      "Epoch 48, Iteration 0, loss = 0.0094696\n",
      "Epoch 48, Iteration 10, loss = 0.0102679\n",
      "Epoch 48, Iteration 20, loss = 0.0015614\n",
      "Epoch 48, Iteration 30, loss = 0.0008364\n",
      "Epoch 48, Iteration 40, loss = 0.1055565\n",
      "Epoch 48, Iteration 50, loss = 0.0011789\n",
      "Epoch 48, Iteration 60, loss = 0.0002522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Iteration 70, loss = 0.0000990\n",
      "Epoch 48, Iteration 80, loss = 0.0006239\n",
      "Epoch 48, Iteration 90, loss = 0.0001864\n",
      "Epoch 48, Iteration 100, loss = 0.0001477\n",
      "Epoch 48, Iteration 110, loss = 0.0000007\n",
      "Epoch 48, Iteration 120, loss = 0.0004082\n",
      "Epoch 48, Iteration 130, loss = 0.0005798\n",
      "Epoch 48, Iteration 140, loss = 0.0000012\n",
      "Epoch 48, Iteration 150, loss = 0.0002419\n",
      "Epoch 48, Iteration 160, loss = 0.0000006\n",
      "Epoch 48, Iteration 170, loss = 0.0000496\n",
      "Epoch 48, Iteration 180, loss = 0.0000122\n",
      "Epoch 48, Iteration 190, loss = 0.0049163\n",
      "Epoch 48, Iteration 200, loss = 0.0027031\n",
      "Epoch 48, Iteration 210, loss = 0.0000399\n",
      "Epoch 48, Iteration 220, loss = 0.0000454\n",
      "Epoch 48, Iteration 230, loss = 0.0100694\n",
      "Got 244 / 347 correct (70.32)\n",
      "Epoch 49, Iteration 0, loss = 0.0001623\n",
      "Epoch 49, Iteration 10, loss = 0.0403408\n",
      "Epoch 49, Iteration 20, loss = 0.0001111\n",
      "Epoch 49, Iteration 30, loss = 0.0000022\n",
      "Epoch 49, Iteration 40, loss = 0.0008576\n",
      "Epoch 49, Iteration 50, loss = 0.0003376\n",
      "Epoch 49, Iteration 60, loss = 0.0033114\n",
      "Epoch 49, Iteration 70, loss = 0.0000002\n",
      "Epoch 49, Iteration 80, loss = 0.0000615\n",
      "Epoch 49, Iteration 90, loss = 0.0004514\n",
      "Epoch 49, Iteration 100, loss = 0.0000683\n",
      "Epoch 49, Iteration 110, loss = 0.0000410\n",
      "Epoch 49, Iteration 120, loss = 0.0000055\n",
      "Epoch 49, Iteration 130, loss = 0.0003329\n",
      "Epoch 49, Iteration 140, loss = 0.0017036\n",
      "Epoch 49, Iteration 150, loss = 0.0009255\n",
      "Epoch 49, Iteration 160, loss = 0.0012611\n",
      "Epoch 49, Iteration 170, loss = 0.0001034\n",
      "Epoch 49, Iteration 180, loss = 0.0853416\n",
      "Epoch 49, Iteration 190, loss = 0.0000686\n",
      "Epoch 49, Iteration 200, loss = 0.0001731\n",
      "Epoch 49, Iteration 210, loss = 0.0006668\n",
      "Epoch 49, Iteration 220, loss = 0.0001034\n",
      "Epoch 49, Iteration 230, loss = 0.0298230\n",
      "Got 243 / 347 correct (70.03)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define neural network\n",
    "model = MyNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)\n",
    "\n",
    "print_every = 10\n",
    "train_model(model, optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 243 / 347 correct (70.03)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7002881844380403, tensor(0.3135, device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set accuracy\n",
    "check_accuracy(loader_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try getting Pre-trained Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.8.2', 'alexnet', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     train_data = train_data#.to('cuda')\n",
    "#     model.to('cuda')\n",
    "for t, data in enumerate(loader_train): \n",
    "    with torch.no_grad():\n",
    "        output = model()\n",
    "    # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "    print(output[0])\n",
    "    # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# vgg19 = torchvision.models.vgg19(pretrained=True)\n",
    "\n",
    "# vgg19.classifier[1] = nn.Conv2d(vgg19.classifier[1].in_channels,5,1,1)\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    " \n",
    "squeezenet = models.squeezenet1_1(pretrained=True, progress=True)\n",
    "# Replace the last layer with one with the correct number of channels\n",
    "network.load_state_dict\n",
    "num_ftr = squeezenet.classifier[1].in_channels\n",
    "squeezenet.classifier[1] = nn.Conv2d(num_ftr, 5, 1, 1)\n",
    "# squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16()\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(neutral_faces, smiling_faces, eyesclosed_faces, surprised_faces, sunglasses_faces, n): \n",
    "# def test(neutral_faces,smiling_faces,eyesclosed_faces, n): \n",
    "    '''\n",
    "    Function to test that I am able to recontruct the original image with after all the reshaping and shaping.\n",
    "    Checking the dimensions and shape as well. \n",
    "    '''\n",
    "    print(neutral_faces.shape)\n",
    "\n",
    "    plt.subplot(1,5,1)\n",
    "    plt.imshow((neutral_faces[:,n]).reshape((224,224)))\n",
    "    plt.subplot(1,5,2)\n",
    "    plt.imshow((smiling_faces[:,n]).reshape((224,224)))\n",
    "    plt.subplot(1,5,3)\n",
    "    plt.imshow((eyesclosed_faces[:,n]).reshape((224,224)))\n",
    "    plt.subplot(1,5,4)\n",
    "    plt.imshow((surprised_faces[:,n]).reshape((224,224)))\n",
    "    plt.subplot(1,5,5)\n",
    "    plt.imshow((sunglasses_faces[:,n]).reshape((224,224)))\n",
    "\n",
    "# Executing test function        \n",
    "# test(neutral_faces, smiling_faces, eyesclosed_faces, surprised_faces, sunglasses_faces, 25)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/27 to do next:\n",
    "- need dataloader\n",
    "- figure out if data is already centered (if not, how to do it for PCA)\n",
    "- feature extraction (PCA)\n",
    "- train our ELMAN RNN (link for how to use RNN with Pytorch: https://www.kaggle.com/kanncaa1/recurrent-neural-network-with-pytorch, https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)\n",
    "- find optimal weights\n",
    "- test\n",
    "- try out other types of netral networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference* Any publication using this database must reference to this:\n",
    "- Website: http://tdface.ece.tufts.edu/ and this\n",
    "- Paper: Panetta, Karen, Qianwen Wan, Sos Agaian, Srijith Rajeev, Shreyas Kamath, Rahul Rajendran, Shishir Rao et al. \"A comprehensive database for benchmarking imaging systems.\" IEEE Transactions on Pattern Analysis and Machine Intelligence (2018).\n",
    "- R Vemulapalli, A Agarwala, A Compact Embedding for Facial Expression Similarity, CoRR, abs/1811.11283, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
